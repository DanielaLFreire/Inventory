# Principal.py - VERSÃƒO COMPLETA COM LAS/LAZ E PREVIEW EXPANDIDO
"""
Sistema Integrado de InventÃ¡rio Florestal - GreenVista
PÃ¡gina principal do sistema com upload de dados e navegaÃ§Ã£o
VERSÃƒO COMPLETA: Inclui processamento LAS/LAZ, persistÃªncia total, interface completa, preview expandido
"""

import streamlit as st
import pandas as pd
import numpy as np
import traceback
import warnings

warnings.filterwarnings('ignore')

# Importar componentes do sistema
from ui.sidebar import criar_sidebar_melhorada, obter_status_sistema_completo
from ui.components import (
    configurar_pagina_greenvista,
    criar_cabecalho_greenvista,
    criar_navegacao_rapida_botoes,
    criar_secao_instrucoes,
    mostrar_alertas_sistema,
    mostrar_empresa)

# Importar processadores CORRIGIDOS
from utils.arquivo_handler import carregar_arquivo_seguro
from config.configuracoes_globais import (
    inicializar_configuracoes_globais,
    obter_configuracao_global,
    aplicar_filtros_configuracao_global
)

# Importar processador LAS se disponÃ­vel
try:
    from processors.las_processor_integrado import (
        ProcessadorLASIntegrado,
        integrar_com_pagina_lidar
    )
    PROCESSAMENTO_LAS_DISPONIVEL = True
except ImportError:
    PROCESSAMENTO_LAS_DISPONIVEL = False


# Configurar pÃ¡gina
configurar_pagina_greenvista("PÃ¡gina Principal", "./images/logo.png")


def verificar_disponibilidade_las():
    """Verifica se processamento LAS estÃ¡ disponÃ­vel no sistema"""
    if not PROCESSAMENTO_LAS_DISPONIVEL:
        return False, ["MÃ³dulo las_processor_integrado nÃ£o encontrado"]

    try:
        return integrar_com_pagina_lidar(), []
    except Exception as e:
        return False, [str(e)]


def processar_dados_inventario(arquivo_inventario):
    """
    Processa e valida dados do inventÃ¡rio florestal
    VERSÃƒO CORRIGIDA: Usa funÃ§Ã£o segura de carregamento

    Args:
        arquivo_inventario: Arquivo de inventÃ¡rio carregado OU DataFrame

    Returns:
        DataFrame processado ou None se erro
    """
    try:
        if arquivo_inventario is None:
            return None

        # CORREÃ‡ÃƒO: Usar funÃ§Ã£o segura que trata DataFrames
        with st.spinner("ğŸ”„ Carregando dados de inventÃ¡rio..."):
            df_inventario = carregar_arquivo_seguro(arquivo_inventario, "inventÃ¡rio")

        if df_inventario is None:
            st.error("âŒ NÃ£o foi possÃ­vel carregar o arquivo de inventÃ¡rio")
            return None

        # Verificar se Ã© DataFrame
        if not isinstance(df_inventario, pd.DataFrame):
            st.error("âŒ Dados de inventÃ¡rio invÃ¡lidos")
            return None

        # Validar estrutura bÃ¡sica
        colunas_obrigatorias = ['D_cm', 'H_m', 'talhao', 'parcela']
        colunas_faltantes = [col for col in colunas_obrigatorias if col not in df_inventario.columns]

        if colunas_faltantes:
            st.error(f"âŒ Colunas obrigatÃ³rias faltantes: {colunas_faltantes}")
            mostrar_colunas_disponiveis(df_inventario)
            return None

        # Limpar e validar dados
        df_limpo = limpar_dados_inventario(df_inventario)

        if len(df_limpo) == 0:
            st.error("âŒ Nenhum registro vÃ¡lido apÃ³s limpeza dos dados")
            return None

        # Mostrar estatÃ­sticas
        mostrar_estatisticas_inventario(df_limpo, df_inventario)

        st.success(f"âœ… InventÃ¡rio processado: {len(df_limpo)} registros vÃ¡lidos")

        return df_limpo

    except Exception as e:
        st.error(f"âŒ Erro ao processar inventÃ¡rio: {e}")
        with st.expander("ğŸ” Detalhes do erro"):
            st.code(traceback.format_exc())
        return None


def processar_dados_cubagem(arquivo_cubagem):
    """
    Processa e valida dados de cubagem
    VERSÃƒO CORRIGIDA: Usa funÃ§Ã£o segura de carregamento

    Args:
        arquivo_cubagem: Arquivo de cubagem carregado OU DataFrame

    Returns:
        DataFrame processado ou None se erro
    """
    try:
        if arquivo_cubagem is None:
            return None

        # CORREÃ‡ÃƒO: Usar funÃ§Ã£o segura que trata DataFrames
        with st.spinner("ğŸ”„ Carregando dados de cubagem..."):
            df_cubagem = carregar_arquivo_seguro(arquivo_cubagem, "cubagem")

        if df_cubagem is None:
            st.error("âŒ NÃ£o foi possÃ­vel carregar o arquivo de cubagem")
            return None

        # Verificar se Ã© DataFrame
        if not isinstance(df_cubagem, pd.DataFrame):
            st.error("âŒ Dados de cubagem invÃ¡lidos")
            return None

        # Validar estrutura bÃ¡sica
        colunas_obrigatorias = ['arv', 'talhao', 'd_cm', 'h_m', 'D_cm', 'H_m']
        colunas_faltantes = [col for col in colunas_obrigatorias if col not in df_cubagem.columns]

        if colunas_faltantes:
            st.error(f"âŒ Colunas obrigatÃ³rias faltantes: {colunas_faltantes}")
            mostrar_colunas_disponiveis(df_cubagem)
            return None

        # Limpar e validar dados
        df_limpo = limpar_dados_cubagem(df_cubagem)

        if len(df_limpo) == 0:
            st.error("âŒ Nenhum registro vÃ¡lido apÃ³s limpeza dos dados")
            return None

        # Mostrar estatÃ­sticas
        mostrar_estatisticas_cubagem(df_limpo, df_cubagem)

        st.success(f"âœ… Cubagem processada: {len(df_limpo)} registros vÃ¡lidos")

        return df_limpo

    except Exception as e:
        st.error(f"âŒ Erro ao processar cubagem: {e}")
        with st.expander("ğŸ” Detalhes do erro"):
            st.code(traceback.format_exc())
        return None


def limpar_dados_inventario(df_inventario):
    """
    Limpa e valida dados do inventÃ¡rio
    VERSÃƒO CORRIGIDA: Melhor tratamento de erros

    Args:
        df_inventario: DataFrame bruto do inventÃ¡rio

    Returns:
        DataFrame limpo
    """
    if not isinstance(df_inventario, pd.DataFrame):
        st.error("âŒ Dados de inventÃ¡rio nÃ£o sÃ£o um DataFrame vÃ¡lido")
        return pd.DataFrame()

    df_limpo = df_inventario.copy()

    # Converter colunas para tipos apropriados
    try:
        df_limpo['D_cm'] = pd.to_numeric(df_limpo['D_cm'], errors='coerce')
        df_limpo['H_m'] = pd.to_numeric(df_limpo['H_m'], errors='coerce')
        df_limpo['talhao'] = pd.to_numeric(df_limpo['talhao'], errors='coerce').astype('Int64')
        df_limpo['parcela'] = pd.to_numeric(df_limpo['parcela'], errors='coerce').astype('Int64')

        # Idade se disponÃ­vel
        if 'idade_anos' in df_limpo.columns:
            df_limpo['idade_anos'] = pd.to_numeric(df_limpo['idade_anos'], errors='coerce')

        # CÃ³digo se disponÃ­vel
        if 'cod' in df_limpo.columns:
            df_limpo['cod'] = df_limpo['cod'].astype(str)

    except Exception as e:
        st.warning(f"âš ï¸ Problema na conversÃ£o de tipos: {e}")

    # Remover registros invÃ¡lidos
    try:
        mask_valido = (
                df_limpo['D_cm'].notna() &
                df_limpo['H_m'].notna() &
                df_limpo['talhao'].notna() &
                df_limpo['parcela'].notna() &
                (df_limpo['D_cm'] > 0) &
                (df_limpo['H_m'] > 1.3)  # Altura mÃ­nima realÃ­stica
        )

        df_limpo = df_limpo[mask_valido]

    except Exception as e:
        st.warning(f"âš ï¸ Problema na filtragem bÃ¡sica: {e}")

    # Remover outliers extremos
    try:
        # Outliers de DAP (usando IQR)
        if 'D_cm' in df_limpo.columns and len(df_limpo) > 0:
            Q1_dap = df_limpo['D_cm'].quantile(0.25)
            Q3_dap = df_limpo['D_cm'].quantile(0.75)
            IQR_dap = Q3_dap - Q1_dap
            limite_inf_dap = Q1_dap - 3 * IQR_dap
            limite_sup_dap = Q3_dap + 3 * IQR_dap

            # Outliers de altura
            Q1_h = df_limpo['H_m'].quantile(0.25)
            Q3_h = df_limpo['H_m'].quantile(0.75)
            IQR_h = Q3_h - Q1_h
            limite_inf_h = Q1_h - 3 * IQR_h
            limite_sup_h = Q3_h + 3 * IQR_h

            # Aplicar filtros de outliers
            mask_outliers = (
                    (df_limpo['D_cm'] >= limite_inf_dap) &
                    (df_limpo['D_cm'] <= limite_sup_dap) &
                    (df_limpo['H_m'] >= limite_inf_h) &
                    (df_limpo['H_m'] <= limite_sup_h)
            )

            df_limpo = df_limpo[mask_outliers]

    except Exception as e:
        st.warning(f"âš ï¸ Problema na remoÃ§Ã£o de outliers: {e}")

    return df_limpo


def limpar_dados_cubagem(df_cubagem):
    """
    Limpa e valida dados de cubagem
    VERSÃƒO CORRIGIDA: Melhor tratamento de erros

    Args:
        df_cubagem: DataFrame bruto da cubagem

    Returns:
        DataFrame limpo
    """
    if not isinstance(df_cubagem, pd.DataFrame):
        st.error("âŒ Dados de cubagem nÃ£o sÃ£o um DataFrame vÃ¡lido")
        return pd.DataFrame()

    df_limpo = df_cubagem.copy()

    # Converter colunas para tipos apropriados
    try:
        df_limpo['arv'] = pd.to_numeric(df_limpo['arv'], errors='coerce').astype('Int64')
        df_limpo['talhao'] = pd.to_numeric(df_limpo['talhao'], errors='coerce').astype('Int64')
        df_limpo['d_cm'] = pd.to_numeric(df_limpo['d_cm'], errors='coerce')
        df_limpo['h_m'] = pd.to_numeric(df_limpo['h_m'], errors='coerce')
        df_limpo['D_cm'] = pd.to_numeric(df_limpo['D_cm'], errors='coerce')
        df_limpo['H_m'] = pd.to_numeric(df_limpo['H_m'], errors='coerce')

    except Exception as e:
        st.warning(f"âš ï¸ Problema na conversÃ£o de tipos: {e}")

    # Remover registros invÃ¡lidos
    try:
        mask_valido = (
                df_limpo['arv'].notna() &
                df_limpo['talhao'].notna() &
                df_limpo['d_cm'].notna() &
                df_limpo['h_m'].notna() &
                df_limpo['D_cm'].notna() &
                df_limpo['H_m'].notna() &
                (df_limpo['d_cm'] > 0) &
                (df_limpo['h_m'] > 0) &
                (df_limpo['D_cm'] > 0) &
                (df_limpo['H_m'] > 1.3)
        )

        df_limpo = df_limpo[mask_valido]

    except Exception as e:
        st.warning(f"âš ï¸ Problema na filtragem bÃ¡sica: {e}")

    # Validar consistÃªncia (diÃ¢metro da seÃ§Ã£o <= DAP)
    try:
        if len(df_limpo) > 0:
            mask_consistente = df_limpo['d_cm'] <= df_limpo['D_cm'] * 1.2  # TolerÃ¢ncia de 20%
            df_limpo = df_limpo[mask_consistente]

    except Exception as e:
        st.warning(f"âš ï¸ Problema na validaÃ§Ã£o de consistÃªncia: {e}")

    return df_limpo


def mostrar_colunas_disponiveis(df):
    """Mostra colunas disponÃ­veis no arquivo"""
    if isinstance(df, pd.DataFrame):
        st.info("ğŸ“‹ Colunas disponÃ­veis no arquivo:")
        colunas_str = ", ".join(df.columns.tolist())
        st.code(colunas_str)
    else:
        st.warning("âš ï¸ NÃ£o foi possÃ­vel exibir colunas - dados invÃ¡lidos")


def mostrar_estatisticas_inventario(df_limpo, df_original):
    """Mostra estatÃ­sticas do inventÃ¡rio processado"""
    try:
        if not isinstance(df_limpo, pd.DataFrame) or not isinstance(df_original, pd.DataFrame):
            st.warning("âš ï¸ NÃ£o foi possÃ­vel calcular estatÃ­sticas - dados invÃ¡lidos")
            return

        with st.expander("ğŸ“Š EstatÃ­sticas do InventÃ¡rio"):
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("Registros Originais", len(df_original))
                st.metric("Registros VÃ¡lidos", len(df_limpo))

            with col2:
                try:
                    talhoes = df_limpo['talhao'].nunique()
                    parcelas = df_limpo.groupby(['talhao', 'parcela']).ngroups
                    st.metric("TalhÃµes", talhoes)
                    st.metric("Parcelas", parcelas)
                except Exception:
                    st.metric("TalhÃµes", "N/A")
                    st.metric("Parcelas", "N/A")

            with col3:
                try:
                    dap_medio = df_limpo['D_cm'].mean()
                    altura_media = df_limpo['H_m'].mean()
                    st.metric("DAP MÃ©dio", f"{dap_medio:.1f} cm")
                    st.metric("Altura MÃ©dia", f"{altura_media:.1f} m")
                except Exception:
                    st.metric("DAP MÃ©dio", "N/A")
                    st.metric("Altura MÃ©dia", "N/A")

            with col4:
                try:
                    dap_min, dap_max = df_limpo['D_cm'].min(), df_limpo['D_cm'].max()
                    alt_min, alt_max = df_limpo['H_m'].min(), df_limpo['H_m'].max()
                    st.metric("DAP Min-Max", f"{dap_min:.1f}-{dap_max:.1f} cm")
                    st.metric("Altura Min-Max", f"{alt_min:.1f}-{alt_max:.1f} m")
                except Exception:
                    st.metric("DAP Min-Max", "N/A")
                    st.metric("Altura Min-Max", "N/A")

            # Mostrar preview dos dados
            st.subheader("ğŸ‘€ Preview dos Dados")
            if len(df_limpo) > 0:
                st.dataframe(df_limpo.head(10), use_container_width=True)
            else:
                st.warning("âš ï¸ Nenhum dado para exibir")

    except Exception as e:
        st.error(f"âŒ Erro ao mostrar estatÃ­sticas: {e}")


def mostrar_estatisticas_cubagem(df_limpo, df_original):
    """Mostra estatÃ­sticas da cubagem processada"""
    try:
        if not isinstance(df_limpo, pd.DataFrame) or not isinstance(df_original, pd.DataFrame):
            st.warning("âš ï¸ NÃ£o foi possÃ­vel calcular estatÃ­sticas - dados invÃ¡lidos")
            return

        with st.expander("ğŸ“Š EstatÃ­sticas da Cubagem"):
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("Registros Originais", len(df_original))
                st.metric("Registros VÃ¡lidos", len(df_limpo))

            with col2:
                try:
                    arvores = df_limpo['arv'].nunique()
                    talhoes = df_limpo['talhao'].nunique()
                    st.metric("Ãrvores Cubadas", arvores)
                    st.metric("TalhÃµes", talhoes)
                except Exception:
                    st.metric("Ãrvores Cubadas", "N/A")
                    st.metric("TalhÃµes", "N/A")

            with col3:
                try:
                    seÃ§Ãµes_por_arvore = df_limpo.groupby(['talhao', 'arv']).size()
                    secoes_media = seÃ§Ãµes_por_arvore.mean()
                    dap_medio = df_limpo['D_cm'].mean()
                    st.metric("SeÃ§Ãµes/Ãrvore", f"{secoes_media:.1f}")
                    st.metric("DAP MÃ©dio", f"{dap_medio:.1f} cm")
                except Exception:
                    st.metric("SeÃ§Ãµes/Ãrvore", "N/A")
                    st.metric("DAP MÃ©dio", "N/A")

            with col4:
                try:
                    altura_media = df_limpo['H_m'].mean()
                    diam_secao_medio = df_limpo['d_cm'].mean()
                    st.metric("Altura MÃ©dia", f"{altura_media:.1f} m")
                    st.metric("DiÃ¢m. SeÃ§Ã£o MÃ©dio", f"{diam_secao_medio:.1f} cm")
                except Exception:
                    st.metric("Altura MÃ©dia", "N/A")
                    st.metric("DiÃ¢m. SeÃ§Ã£o MÃ©dio", "N/A")

            # Mostrar preview dos dados
            st.subheader("ğŸ‘€ Preview dos Dados")
            if len(df_limpo) > 0:
                st.dataframe(df_limpo.head(10), use_container_width=True)
            else:
                st.warning("âš ï¸ Nenhum dado para exibir")

    except Exception as e:
        st.error(f"âŒ Erro ao mostrar estatÃ­sticas: {e}")


# ================================
# FUNÃ‡Ã•ES DE PREVIEW EXPANDIDO
# ================================

def escolher_modo_preview():
    """Permite escolher entre preview resumido ou detalhado"""
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        modo_detalhado = st.toggle(
            "ğŸ“Š **AnÃ¡lise Detalhada dos Dados**", 
            value=False,
            help="Ative para ver estatÃ­sticas completas de todos os arquivos carregados\n\n" +
                 "â€¢ **Desativado**: Resumo geral e status\n" +
                 "â€¢ **Ativado**: AnÃ¡lise completa com mÃ©tricas, distribuiÃ§Ãµes e qualidade"
        )
    
    return modo_detalhado


def mostrar_preview_inteligente():
    """Mostra preview adequado baseado na escolha do usuÃ¡rio"""
    modo_detalhado = escolher_modo_preview()
    
    if modo_detalhado:
        mostrar_preview_dados_carregados()  # VersÃ£o completa e detalhada
    else:
        mostrar_resumo_geral_dados()  # VersÃ£o resumida e concisa


def mostrar_resumo_geral_dados():
    """
    Mostra um resumo conciso e direto de todos os dados carregados
    VERSÃƒO OTIMIZADA: Para uso como modo 'simples' vs detalhado
    """
    st.subheader("ğŸ“Š Resumo dos Dados Carregados")
    
    # Verificar dados disponÃ­veis
    tem_inventario = hasattr(st.session_state, 'dados_inventario') and st.session_state.dados_inventario is not None
    tem_cubagem = hasattr(st.session_state, 'dados_cubagem') and st.session_state.dados_cubagem is not None
    tem_las = hasattr(st.session_state, 'arquivo_las') and st.session_state.arquivo_las is not None
    tem_metricas_lidar = hasattr(st.session_state, 'arquivo_metricas_lidar') and st.session_state.arquivo_metricas_lidar is not None
    tem_shapefile = hasattr(st.session_state, 'arquivo_shapefile') and st.session_state.arquivo_shapefile is not None
    tem_coordenadas = hasattr(st.session_state, 'arquivo_coordenadas') and st.session_state.arquivo_coordenadas is not None
    
    # === STATUS GERAL ===
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if tem_inventario and tem_cubagem:
            st.success("âœ… **Dados Core**\nCompletos")
            if tem_inventario:
                df_inv = st.session_state.dados_inventario
                st.caption(f"ğŸ“‹ {len(df_inv):,} registros")
        else:
            st.error("âŒ **Dados Core**\nIncompletos")
            
    with col2:
        # Contar arquivos extras
        extras = sum([tem_las, tem_metricas_lidar, tem_shapefile, tem_coordenadas])
        if extras > 0:
            st.info(f"ğŸ“ **{extras} Arquivos**\nAdicionais")
            extras_lista = []
            if tem_las or tem_metricas_lidar:
                extras_lista.append("ğŸ›©ï¸ LiDAR")
            if tem_shapefile:
                extras_lista.append("ğŸ—ºï¸ SHP")
            if tem_coordenadas:
                extras_lista.append("ğŸ“ Coord")
            st.caption(" â€¢ ".join(extras_lista))
        else:
            st.warning("ğŸ“ **Sem Arquivos**\nAdicionais")
    
    with col3:
        # Status de processamento
        processados = 0
        total_processos = 3
        
        if hasattr(st.session_state, 'resultados_hipsometricos') and st.session_state.resultados_hipsometricos is not None:
            processados += 1
        if hasattr(st.session_state, 'resultados_volumetricos') and st.session_state.resultados_volumetricos is not None:
            processados += 1
        if hasattr(st.session_state, 'inventario_processado') and st.session_state.inventario_processado is not None:
            processados += 1
            
        if processados == total_processos:
            st.success("ğŸ‰ **AnÃ¡lises**\nCompletas")
        elif processados > 0:
            st.warning(f"âš ï¸ **{processados}/{total_processos} Etapas**\nConcluÃ­das")
        else:
            st.info("â³ **AnÃ¡lises**\nPendentes")
        
    with col4:
        # LiDAR especÃ­fico
        if hasattr(st.session_state, 'dados_lidar') and st.session_state.dados_lidar is not None:
            st.success("ğŸ›©ï¸ **LiDAR**\nIntegrado")
            stats = st.session_state.dados_lidar.get('stats_comparacao', {})
            if 'r2' in stats:
                r2 = stats['r2']
                st.caption(f"ğŸ“Š RÂ²: {r2:.3f}")
        elif tem_las or tem_metricas_lidar:
            st.warning("ğŸ›©ï¸ **LiDAR**\nDisponÃ­vel")
            st.caption("â³ NÃ£o processado")
        else:
            st.info("ğŸ›©ï¸ **LiDAR**\nOpcional")

    # === MÃ‰TRICAS RÃPIDAS ===
    if tem_inventario and tem_cubagem:
        st.markdown("---")
        col1, col2, col3, col4, col5 = st.columns(5)
        
        try:
            df_inv = st.session_state.dados_inventario
            df_cub = st.session_state.dados_cubagem
            
            with col1:
                talhoes = df_inv['talhao'].nunique()
                st.metric("ğŸŒ³ TalhÃµes", talhoes)
                
            with col2:
                parcelas = df_inv.groupby(['talhao', 'parcela']).ngroups
                st.metric("ğŸ“ Parcelas", parcelas)
                
            with col3:
                arvores_cubadas = df_cub['arv'].nunique()
                st.metric("ğŸ“ Ãrvores Cubadas", arvores_cubadas)
                
            with col4:
                dap_medio = df_inv['D_cm'].mean()
                st.metric("ğŸ“ DAP MÃ©dio", f"{dap_medio:.1f} cm")
                
            with col5:
                altura_media = df_inv['H_m'].mean()
                st.metric("ğŸ“ Altura MÃ©dia", f"{altura_media:.1f} m")
                
        except Exception:
            st.caption("âš ï¸ Erro ao calcular mÃ©tricas rÃ¡pidas")

    # === PRÃ“XIMOS PASSOS ===
    st.markdown("---")
    st.markdown("### ğŸš€ PrÃ³ximos Passos")
    
    if not (tem_inventario and tem_cubagem):
        st.error("**1.** ğŸ“ Carregue dados de InventÃ¡rio e Cubagem na sidebar")
        return
    
    # Verificar configuraÃ§Ã£o
    try:
        from config.configuracoes_globais import obter_configuracao_global
        config_global = obter_configuracao_global()
        configurado = config_global.get('configurado', False)
        
        if not configurado:
            st.warning("**1.** âš™ï¸ Configure o sistema na Etapa 0")
            st.info("**2.** ğŸ”„ Execute etapas 1-3 em sequÃªncia")
            return
    except:
        st.warning("**1.** âš™ï¸ Configure o sistema na Etapa 0")
        return
    
    # Verificar etapas executadas
    hip_ok = hasattr(st.session_state, 'resultados_hipsometricos') and st.session_state.resultados_hipsometricos is not None
    vol_ok = hasattr(st.session_state, 'resultados_volumetricos') and st.session_state.resultados_volumetricos is not None
    inv_ok = hasattr(st.session_state, 'inventario_processado') and st.session_state.inventario_processado is not None
    
    if not hip_ok:
        st.info("**1.** ğŸŒ³ Execute Etapa 1 - Modelos HipsomÃ©tricos")
    elif not vol_ok:
        st.info("**1.** ğŸ“Š Execute Etapa 2 - Modelos VolumÃ©tricos")
    elif not inv_ok:
        st.info("**1.** ğŸ“ˆ Execute Etapa 3 - InventÃ¡rio Final")
    else:
        st.success("ğŸ‰ **Todas as etapas principais concluÃ­das!**")
        
        # SugestÃµes extras
        if tem_las or tem_metricas_lidar:
            if not hasattr(st.session_state, 'dados_lidar') or st.session_state.dados_lidar is None:
                st.info("ğŸ’¡ **Opcional:** Processe dados LiDAR na AnÃ¡lise LiDAR")
        else:
            st.info("ğŸ’¡ **Opcional:** Carregue dados LiDAR para anÃ¡lises avanÃ§adas")

    # === INFORMAÃ‡Ã•ES DE SESSÃƒO ===
    with st.expander("ğŸ’¾ InformaÃ§Ãµes da SessÃ£o"):
        st.markdown("""
        **âœ… Dados Persistentes:**
        - Todos os arquivos permanecem na sessÃ£o
        - Navegue livremente entre pÃ¡ginas
        - Resultados sÃ£o mantidos atÃ© fechar o navegador
        
        **âš ï¸ Dados sÃ£o perdidos ao:**
        - Fechar/recarregar o navegador
        - Timeout por inatividade prolongada
        
        **ğŸ’¡ Dica:** FaÃ§a download dos resultados importantes!
        """)
        
        # Mostrar arquivos atualmente na sessÃ£o
        arquivos_na_sessao = []
        if tem_inventario:
            arquivos_na_sessao.append("ğŸ“‹ InventÃ¡rio")
        if tem_cubagem:
            arquivos_na_sessao.append("ğŸ“ Cubagem")
        if tem_las:
            arquivos_na_sessao.append("ğŸ›©ï¸ Arquivo LAS")
        if tem_metricas_lidar:
            arquivos_na_sessao.append("ğŸ“Š MÃ©tricas LiDAR")
        if tem_shapefile:
            arquivos_na_sessao.append("ğŸ—ºï¸ Shapefile")
        if tem_coordenadas:
            arquivos_na_sessao.append("ğŸ“ Coordenadas")
            
        if arquivos_na_sessao:
            st.success("**Na sessÃ£o:** " + " â€¢ ".join(arquivos_na_sessao))
        else:
            st.info("Nenhum arquivo na sessÃ£o")


def mostrar_preview_dados_carregados():
    """
    Mostra preview completo de todos os dados carregados
    VERSÃƒO COM EXPANDERS: Organizado como mostrar_estatisticas_cubagem
    """
    try:
        st.subheader("ğŸ“Š Dados Carregados no Sistema")

        # === DADOS DE INVENTÃRIO ===
        if hasattr(st.session_state, 'dados_inventario') and st.session_state.dados_inventario is not None:
            df_inventario = st.session_state.dados_inventario

            if isinstance(df_inventario, pd.DataFrame) and len(df_inventario) > 0:
                st.success(f"âœ… **InventÃ¡rio processado:** {len(df_inventario)} registros vÃ¡lidos")

                with st.expander("ğŸ“Š EstatÃ­sticas do InventÃ¡rio"):
                    # MÃ©tricas principais
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ğŸ“Š Registros", f"{len(df_inventario):,}")
                        talhoes = df_inventario['talhao'].nunique()
                        st.metric("ğŸŒ³ TalhÃµes", talhoes)
                    with col2:
                        parcelas = df_inventario.groupby(['talhao', 'parcela']).ngroups
                        st.metric("ğŸ“ Parcelas", parcelas)
                        try:
                            dap_medio = df_inventario['D_cm'].mean()
                            st.metric("ğŸ“ DAP MÃ©dio", f"{dap_medio:.1f} cm")
                        except:
                            st.metric("ğŸ“ DAP MÃ©dio", "N/A")
                    with col3:
                        try:
                            altura_media = df_inventario['H_m'].mean()
                            st.metric("ğŸ“ Altura MÃ©dia", f"{altura_media:.1f} m")
                            dap_min, dap_max = df_inventario['D_cm'].min(), df_inventario['D_cm'].max()
                            st.metric("ğŸ“Š DAP Min-Max", f"{dap_min:.1f}-{dap_max:.1f}")
                        except:
                            st.metric("ğŸ“ Altura MÃ©dia", "N/A")
                            st.metric("ğŸ“Š DAP Min-Max", "N/A")
                    with col4:
                        try:
                            alt_min, alt_max = df_inventario['H_m'].min(), df_inventario['H_m'].max()
                            st.metric("ğŸ“ Alt Min-Max", f"{alt_min:.1f}-{alt_max:.1f}")
                            # Ãrea basal total
                            area_basal = (df_inventario['D_cm'] ** 2 * np.pi / 40000).sum()
                            st.metric("ğŸ¯ Ãrea Basal", f"{area_basal:.1f} mÂ²")
                        except:
                            st.metric("ğŸ“ Alt Min-Max", "N/A")
                            st.metric("ğŸ¯ Ãrea Basal", "N/A")

                    # InformaÃ§Ãµes de idade se disponÃ­vel
                    if 'idade_anos' in df_inventario.columns:
                        try:
                            idade_info = df_inventario.groupby('talhao')['idade_anos'].agg(['mean', 'min', 'max'])
                            st.info(f"ğŸ• **Idade:** {idade_info['mean'].mean():.1f} anos (mÃ©dia geral)")
                        except Exception:
                            pass

                    # Preview dos dados
                    st.subheader("ğŸ‘€ Preview dos Dados")
                    if len(df_inventario) > 0:
                        st.dataframe(df_inventario.head(10), use_container_width=True)
                    else:
                        st.warning("âš ï¸ Nenhum dado para exibir")

                    # DistribuiÃ§Ãµes opcionais
                    if st.checkbox("ğŸ“Š Mostrar DistribuiÃ§Ãµes", key="dist_inventario"):
                        col_dist1, col_dist2 = st.columns(2)
                        with col_dist1:
                            st.write("**DistribuiÃ§Ã£o DAP**")
                            try:
                                hist_dap = df_inventario['D_cm'].value_counts().sort_index().head(20)
                                st.bar_chart(hist_dap)
                            except:
                                st.caption("âš ï¸ Erro ao gerar distribuiÃ§Ã£o DAP")
                        with col_dist2:
                            st.write("**Ãrvores por TalhÃ£o**")
                            try:
                                arvores_talhao = df_inventario['talhao'].value_counts().sort_index()
                                st.bar_chart(arvores_talhao)
                            except:
                                st.caption("âš ï¸ Erro ao gerar distribuiÃ§Ã£o por talhÃ£o")
            else:
                st.warning("âš ï¸ InventÃ¡rio existe mas estÃ¡ vazio ou invÃ¡lido")
        else:
            st.error("âŒ **Dados de InventÃ¡rio:** NÃ£o carregados")

        # === DADOS DE CUBAGEM ===
        if hasattr(st.session_state, 'dados_cubagem') and st.session_state.dados_cubagem is not None:
            df_cubagem = st.session_state.dados_cubagem

            if isinstance(df_cubagem, pd.DataFrame) and len(df_cubagem) > 0:
                arvores_cubadas = df_cubagem['arv'].nunique()
                st.success(f"âœ… **Cubagem processada:** {arvores_cubadas} Ã¡rvores cubadas")

                with st.expander("ğŸ“Š EstatÃ­sticas da Cubagem"):
                    # MÃ©tricas principais
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ğŸ“ Ãrvores", arvores_cubadas)
                        total_secoes = len(df_cubagem)
                        st.metric("ğŸ“Š SeÃ§Ãµes", f"{total_secoes:,}")
                    with col2:
                        talhoes_cub = df_cubagem['talhao'].nunique()
                        st.metric("ğŸŒ³ TalhÃµes", talhoes_cub)
                        try:
                            secoes_media = df_cubagem.groupby(['talhao', 'arv']).size().mean()
                            st.metric("ğŸ“ SeÃ§Ãµes/Ãrvore", f"{secoes_media:.1f}")
                        except:
                            st.metric("ğŸ“ SeÃ§Ãµes/Ãrvore", "N/A")
                    with col3:
                        try:
                            dap_medio_cub = df_cubagem['D_cm'].mean()
                            st.metric("ğŸ“Š DAP MÃ©dio", f"{dap_medio_cub:.1f} cm")
                            altura_media_cub = df_cubagem['H_m'].mean()
                            st.metric("ğŸ“ Alt. MÃ©dia", f"{altura_media_cub:.1f} m")
                        except:
                            st.metric("ğŸ“Š DAP MÃ©dio", "N/A")
                            st.metric("ğŸ“ Alt. MÃ©dia", "N/A")
                    with col4:
                        try:
                            diam_secao_medio = df_cubagem['d_cm'].mean()
                            st.metric("ğŸ¯ DiÃ¢m. SeÃ§Ã£o", f"{diam_secao_medio:.1f} cm")
                            # ConsistÃªncia d/DAP
                            df_cubagem['razao_d_D'] = df_cubagem['d_cm'] / df_cubagem['D_cm']
                            consistencia = df_cubagem['razao_d_D'].mean()
                            st.metric("âš–ï¸ ConsistÃªncia", f"{consistencia:.2f}")
                        except:
                            st.metric("ğŸ¯ DiÃ¢m. SeÃ§Ã£o", "N/A")
                            st.metric("âš–ï¸ ConsistÃªncia", "N/A")

                    # AnÃ¡lise de qualidade
                    try:
                        if 'razao_d_D' in df_cubagem.columns:
                            consistencia_pct = (df_cubagem['razao_d_D'] <= 1.0).mean() * 100
                            if consistencia_pct > 95:
                                st.success(
                                    f"ğŸ¯ **Excelente qualidade:** {consistencia_pct:.1f}% das seÃ§Ãµes consistentes")
                            elif consistencia_pct > 85:
                                st.info(f"ğŸ‘ **Boa qualidade:** {consistencia_pct:.1f}% das seÃ§Ãµes consistentes")
                            else:
                                st.warning(
                                    f"âš ï¸ **Verificar qualidade:** {consistencia_pct:.1f}% das seÃ§Ãµes consistentes")
                    except:
                        pass

                    # Preview dos dados
                    st.subheader("ğŸ‘€ Preview dos Dados")
                    if len(df_cubagem) > 0:
                        st.dataframe(df_cubagem.head(10), use_container_width=True)
                    else:
                        st.warning("âš ï¸ Nenhum dado para exibir")

                    # AnÃ¡lise por Ã¡rvore opcional
                    if st.checkbox("ğŸŒ³ AnÃ¡lise Detalhada por Ãrvore", key="analise_arvore_detalhada"):
                        try:
                            arvore_stats = df_cubagem.groupby(['talhao', 'arv']).agg({
                                'D_cm': 'first',
                                'H_m': 'first',
                                'd_cm': ['count', 'mean', 'std'],
                                'h_m': 'max'
                            }).round(2)

                            arvore_stats.columns = ['DAP', 'Altura', 'N_Secoes', 'Diam_Medio', 'Diam_Std', 'Alt_Cubada']
                            st.dataframe(arvore_stats.head(15), use_container_width=True)
                        except Exception as e:
                            st.error(f"âš ï¸ Erro na anÃ¡lise por Ã¡rvore: {e}")
            else:
                st.warning("âš ï¸ Cubagem existe mas estÃ¡ vazia ou invÃ¡lida")
        else:
            st.error("âŒ **Dados de Cubagem:** NÃ£o carregados")

        # === DADOS DE ÃREA (ARQUIVOS ESPACIAIS) ===
        arquivos_espaciais_encontrados = False

        # Shapefile
        if hasattr(st.session_state, 'arquivo_shapefile') and st.session_state.arquivo_shapefile is not None:
            arquivo_shapefile = st.session_state.arquivo_shapefile
            arquivos_espaciais_encontrados = True

            st.success("âœ… **Shapefile carregado** - DisponÃ­vel para cÃ¡lculo preciso de Ã¡reas")

            with st.expander("ğŸ—ºï¸ InformaÃ§Ãµes do Shapefile"):
                col1, col2, col3 = st.columns(3)
                with col1:
                    nome_arquivo = getattr(arquivo_shapefile, 'name', 'shapefile.zip')
                    st.metric("ğŸ“ Arquivo", nome_arquivo.split('.')[-1].upper())
                    st.metric("ğŸ“„ Nome", nome_arquivo[:20] + "..." if len(nome_arquivo) > 20 else nome_arquivo)
                with col2:
                    try:
                        tamanho_kb = getattr(arquivo_shapefile, 'size', 0) / 1024
                        st.metric("ğŸ’¾ Tamanho", f"{tamanho_kb:.0f} KB")
                    except:
                        st.metric("ğŸ’¾ Tamanho", "N/A")
                    st.metric("ğŸ“Š Status", "âœ… Ativo")
                with col3:
                    st.metric("ğŸ¯ Uso", "CÃ¡lculo de Ã¡reas")
                    st.metric("âš™ï¸ Config", "MÃ©todo SHP")

                st.info(
                    "ğŸ—ºï¸ **Uso recomendado:** Configure na Etapa 0 o mÃ©todo de Ã¡rea como 'Baseado em Shapefile' para cÃ¡lculos precisos")

        # Coordenadas
        if hasattr(st.session_state, 'arquivo_coordenadas') and st.session_state.arquivo_coordenadas is not None:
            arquivo_coordenadas = st.session_state.arquivo_coordenadas
            arquivos_espaciais_encontrados = True

            st.success("âœ… **Coordenadas carregadas** - DisponÃ­veis para anÃ¡lises espaciais")

            with st.expander("ğŸ“ InformaÃ§Ãµes das Coordenadas"):
                col1, col2, col3 = st.columns(3)
                with col1:
                    nome_arquivo = getattr(arquivo_coordenadas, 'name', 'coordenadas.csv')
                    st.metric("ğŸ“ Arquivo", nome_arquivo.split('.')[-1].upper())
                    st.metric("ğŸ“„ Nome", nome_arquivo[:20] + "..." if len(nome_arquivo) > 20 else nome_arquivo)
                with col2:
                    try:
                        tamanho_kb = getattr(arquivo_coordenadas, 'size', 0) / 1024
                        st.metric("ğŸ’¾ Tamanho", f"{tamanho_kb:.0f} KB")
                    except:
                        st.metric("ğŸ’¾ Tamanho", "N/A")
                    st.metric("ğŸ“Š Status", "âœ… Ativo")
                with col3:
                    st.metric("ğŸ¯ Uso", "AnÃ¡lises espaciais")
                    st.metric("ğŸ—ºï¸ Tipo", "Coordenadas XY")

                # Tentar mostrar informaÃ§Ãµes das coordenadas
                try:
                    df_coordenadas = carregar_arquivo_seguro(arquivo_coordenadas, "coordenadas")
                    if df_coordenadas is not None and len(df_coordenadas) > 0:
                        st.info(f"ğŸ“ **{len(df_coordenadas)} coordenadas** carregadas e prontas para uso")

                        # Preview opcional
                        if st.checkbox("ğŸ‘€ Preview das Coordenadas", key="preview_coord_expander"):
                            st.subheader("ğŸ“Š Dados das Coordenadas")
                            st.dataframe(df_coordenadas.head(), use_container_width=True)

                            # EstatÃ­sticas bÃ¡sicas se houver colunas X, Y
                            try:
                                if 'X' in df_coordenadas.columns and 'Y' in df_coordenadas.columns:
                                    col_coord1, col_coord2 = st.columns(2)
                                    with col_coord1:
                                        x_min, x_max = df_coordenadas['X'].min(), df_coordenadas['X'].max()
                                        st.metric("ğŸŒ X Min-Max", f"{x_min:.0f} - {x_max:.0f}")
                                    with col_coord2:
                                        y_min, y_max = df_coordenadas['Y'].min(), df_coordenadas['Y'].max()
                                        st.metric("ğŸŒ Y Min-Max", f"{y_min:.0f} - {y_max:.0f}")
                            except:
                                pass
                except Exception:
                    st.warning("âš ï¸ Erro ao carregar preview das coordenadas")

        if not arquivos_espaciais_encontrados:
            st.info("ğŸ“ **Arquivos de Ãrea:** Nenhum carregado (opcional)")

        # === DADOS LIDAR ===
        dados_lidar_encontrados = False

        # Arquivo LAS/LAZ
        if hasattr(st.session_state, 'arquivo_las') and st.session_state.arquivo_las is not None:
            arquivo_las = st.session_state.arquivo_las
            dados_lidar_encontrados = True

            st.success("âœ… **Arquivo LAS/LAZ carregado** - Pronto para processamento")

            with st.expander("ğŸ›©ï¸ InformaÃ§Ãµes do Arquivo LAS/LAZ"):
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    nome_arquivo = getattr(arquivo_las, 'name', 'arquivo.las')
                    st.metric("ğŸ“ Tipo", nome_arquivo.split('.')[-1].upper())
                    st.metric("ğŸ“„ Nome", nome_arquivo[:15] + "..." if len(nome_arquivo) > 15 else nome_arquivo)
                with col2:
                    try:
                        tamanho_mb = getattr(arquivo_las, 'size', 0) / (1024 * 1024)
                        st.metric("ğŸ’¾ Tamanho", f"{tamanho_mb:.1f} MB")
                    except:
                        st.metric("ğŸ’¾ Tamanho", "N/A")
                    st.metric("ğŸ¯ Uso", "Processamento LiDAR")
                with col3:
                    processado = hasattr(st.session_state,
                                         'dados_lidar_las') and st.session_state.dados_lidar_las is not None
                    st.metric("ğŸ“Š Status", "âœ… Processado" if processado else "â³ Pendente")
                    st.metric("ğŸ”„ AÃ§Ã£o", "ConcluÃ­do" if processado else "Processar")
                with col4:
                    st.metric("ğŸ“ Destino", "AnÃ¡lise LiDAR")
                    st.metric("âš™ï¸ MÃ©todo", "AutomÃ¡tico")

                if not processado:
                    st.info(
                        "ğŸš€ **PrÃ³ximo passo:** Acesse a pÃ¡gina 'AnÃ¡lise LiDAR' para processar o arquivo e extrair mÃ©tricas")

        # Dados LAS processados
        if hasattr(st.session_state, 'dados_lidar_las') and st.session_state.dados_lidar_las is not None:
            dados_las = st.session_state.dados_lidar_las
            dados_lidar_encontrados = True

            if 'df_metricas' in dados_las:
                df_metricas = dados_las['df_metricas']
                st.success(f"âœ… **Dados LAS processados:** {len(df_metricas)} parcelas com mÃ©tricas")

                with st.expander("ğŸ“Š EstatÃ­sticas do Processamento LAS"):
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ğŸ“ Parcelas", len(df_metricas))
                        try:
                            altura_media = df_metricas['altura_media'].mean()
                            st.metric("ğŸ“ Alt. MÃ©dia", f"{altura_media:.1f} m")
                        except:
                            st.metric("ğŸ“ Alt. MÃ©dia", "N/A")
                    with col2:
                        try:
                            pontos_total = df_metricas['n_pontos'].sum()
                            st.metric("ğŸ¯ Total Pontos", f"{pontos_total:,}")
                            densidade_media = df_metricas['densidade'].mean()
                            st.metric("ğŸ“Š Densidade", f"{densidade_media:.1f} pts/mÂ²")
                        except:
                            st.metric("ğŸ¯ Total Pontos", "N/A")
                            st.metric("ğŸ“Š Densidade", "N/A")
                    with col3:
                        try:
                            cobertura_media = df_metricas['cobertura'].mean()
                            st.metric("ğŸŒ³ Cobertura", f"{cobertura_media:.1f}%")
                            if 'altura_max' in df_metricas.columns:
                                altura_max = df_metricas['altura_max'].max()
                                st.metric("ğŸ” Alt. MÃ¡xima", f"{altura_max:.1f} m")
                        except:
                            st.metric("ğŸŒ³ Cobertura", "N/A")
                            st.metric("ğŸ” Alt. MÃ¡xima", "N/A")
                    with col4:
                        try:
                            if 'altura_p95' in df_metricas.columns:
                                altura_p95 = df_metricas['altura_p95'].mean()
                                st.metric("ğŸ“ˆ Alt. P95", f"{altura_p95:.1f} m")
                            if 'biomassa' in df_metricas.columns:
                                biomassa_total = df_metricas['biomassa'].sum()
                                st.metric("ğŸŒ¿ Biomassa", f"{biomassa_total:.0f} kg")
                        except:
                            st.metric("ğŸ“ˆ Alt. P95", "N/A")
                            st.metric("ğŸŒ¿ Biomassa", "N/A")

                    # AnÃ¡lise de qualidade dos dados LAS
                    try:
                        if 'densidade' in df_metricas.columns:
                            densidade_min = df_metricas['densidade'].min()
                            densidade_media = df_metricas['densidade'].mean()

                            if densidade_min > 4:
                                st.success(
                                    f"ğŸ¯ **Excelente densidade:** mÃ­nimo {densidade_min:.1f} pts/mÂ², mÃ©dia {densidade_media:.1f} pts/mÂ²")
                            elif densidade_min > 2:
                                st.info(
                                    f"ğŸ‘ **Boa densidade:** mÃ­nimo {densidade_min:.1f} pts/mÂ², mÃ©dia {densidade_media:.1f} pts/mÂ²")
                            else:
                                st.warning(
                                    f"âš ï¸ **Densidade baixa:** mÃ­nimo {densidade_min:.1f} pts/mÂ², mÃ©dia {densidade_media:.1f} pts/mÂ²")
                    except:
                        pass

                    # Preview das mÃ©tricas
                    st.subheader("ğŸ‘€ Preview das MÃ©tricas LAS")
                    if len(df_metricas) > 0:
                        st.dataframe(df_metricas.head(10), use_container_width=True)
                    else:
                        st.warning("âš ï¸ Nenhuma mÃ©trica para exibir")

        # MÃ©tricas LiDAR prÃ©-processadas
        elif hasattr(st.session_state,
                     'arquivo_metricas_lidar') and st.session_state.arquivo_metricas_lidar is not None:
            arquivo_metricas = st.session_state.arquivo_metricas_lidar
            dados_lidar_encontrados = True

            st.success("âœ… **MÃ©tricas LiDAR carregadas** - Dados prÃ©-processados disponÃ­veis")

            with st.expander("ğŸ“Š InformaÃ§Ãµes das MÃ©tricas LiDAR"):
                col1, col2, col3 = st.columns(3)
                with col1:
                    nome_arquivo = getattr(arquivo_metricas, 'name', 'metricas.csv')
                    st.metric("ğŸ“ Tipo", nome_arquivo.split('.')[-1].upper())
                    st.metric("ğŸ“„ Arquivo", nome_arquivo[:20] + "..." if len(nome_arquivo) > 20 else nome_arquivo)
                with col2:
                    integrado = hasattr(st.session_state, 'dados_lidar') and st.session_state.dados_lidar is not None
                    st.metric("ğŸ“Š Status", "âœ… Integrado" if integrado else "â³ Pendente")
                    st.metric("ğŸ¯ Origem", "PrÃ©-processado")
                with col3:
                    st.metric("ğŸ”„ PrÃ³ximo", "IntegraÃ§Ã£o" if not integrado else "ConcluÃ­do")
                    st.metric("ğŸ“ Destino", "AnÃ¡lise LiDAR")

                if not integrado:
                    st.info(
                        "ğŸš€ **PrÃ³ximo passo:** Acesse a pÃ¡gina 'AnÃ¡lise LiDAR' para integrar com os dados de inventÃ¡rio")

        # Dados LiDAR integrados
        if hasattr(st.session_state, 'dados_lidar') and st.session_state.dados_lidar is not None:
            dados_lidar = st.session_state.dados_lidar
            dados_lidar_encontrados = True

            st.success("âœ… **LiDAR integrado com inventÃ¡rio** - AnÃ¡lise comparativa disponÃ­vel")

            with st.expander("ğŸ”— EstatÃ­sticas da IntegraÃ§Ã£o LiDAR"):
                if 'stats_comparacao' in dados_lidar and dados_lidar['stats_comparacao'] is not None:
                    stats = dados_lidar['stats_comparacao']

                    col1, col2, col3, col4, col5 = st.columns(5)
                    with col1:
                        correlacao = stats.get('correlacao', 0)
                        st.metric("ğŸ“Š CorrelaÃ§Ã£o", f"{correlacao:.3f}")
                        r2 = stats.get('r2', 0)
                        st.metric("ğŸ“ˆ RÂ²", f"{r2:.3f}")
                    with col2:
                        rmse = stats.get('rmse', 0)
                        st.metric("ğŸ“ RMSE", f"{rmse:.2f} m")
                        bias = stats.get('bias', 0)
                        st.metric("âš–ï¸ Bias", f"{bias:+.2f} m")
                    with col3:
                        n_parcelas = stats.get('n_parcelas', 0)
                        st.metric("ğŸ“ Parcelas", n_parcelas)
                        try:
                            mae = stats.get('mae', 0)
                            st.metric("ğŸ“Š MAE", f"{mae:.2f} m")
                        except:
                            st.metric("ğŸ“Š MAE", "N/A")
                    with col4:
                        try:
                            mape = stats.get('mape', 0)
                            st.metric("ğŸ“ˆ MAPE", f"{mape:.1f}%")
                            altura_campo_media = stats.get('altura_campo_media', 0)
                            st.metric("ğŸŒ³ Alt. Campo", f"{altura_campo_media:.1f} m")
                        except:
                            st.metric("ğŸ“ˆ MAPE", "N/A")
                            st.metric("ğŸŒ³ Alt. Campo", "N/A")
                    with col5:
                        try:
                            altura_lidar_media = stats.get('altura_lidar_media', 0)
                            st.metric("ğŸ›©ï¸ Alt. LiDAR", f"{altura_lidar_media:.1f} m")
                            diferenca_media = stats.get('diferenca_media', 0)
                            st.metric("ğŸ“ Diff. MÃ©dia", f"{diferenca_media:+.2f} m")
                        except:
                            st.metric("ğŸ›©ï¸ Alt. LiDAR", "N/A")
                            st.metric("ğŸ“ Diff. MÃ©dia", "N/A")

                    # Interpretar qualidade da correlaÃ§Ã£o
                    st.subheader("ğŸ¯ Qualidade da IntegraÃ§Ã£o")
                    if correlacao >= 0.8:
                        st.success(f"ğŸ¯ **Excelente correlaÃ§Ã£o** entre dados de campo e LiDAR (r = {correlacao:.3f})")
                    elif correlacao >= 0.6:
                        st.info(f"ğŸ‘ **Boa correlaÃ§Ã£o** entre dados de campo e LiDAR (r = {correlacao:.3f})")
                    elif correlacao >= 0.4:
                        st.warning(f"âš ï¸ **CorrelaÃ§Ã£o moderada** entre dados de campo e LiDAR (r = {correlacao:.3f})")
                    else:
                        st.error(f"âŒ **CorrelaÃ§Ã£o fraca** entre dados de campo e LiDAR (r = {correlacao:.3f})")

                    # AnÃ¡lise do RÂ²
                    if r2 >= 0.7:
                        st.success(
                            f"ğŸ“ˆ **Excelente ajuste:** RÂ² = {r2:.3f} (modelo explica {r2 * 100:.1f}% da variaÃ§Ã£o)")
                    elif r2 >= 0.5:
                        st.info(f"ğŸ“Š **Bom ajuste:** RÂ² = {r2:.3f} (modelo explica {r2 * 100:.1f}% da variaÃ§Ã£o)")
                    else:
                        st.warning(
                            f"âš ï¸ **Ajuste moderado:** RÂ² = {r2:.3f} (modelo explica {r2 * 100:.1f}% da variaÃ§Ã£o)")

                # Mostrar alertas se houver
                if 'alertas' in dados_lidar and dados_lidar['alertas']:
                    alertas = dados_lidar['alertas']
                    if len(alertas) > 0:
                        st.subheader("âš ï¸ Alertas da IntegraÃ§Ã£o")
                        for i, alerta in enumerate(alertas[:5], 1):  # Mostrar atÃ© 5 alertas
                            st.warning(f"**{i}.** {alerta}")
                        if len(alertas) > 5:
                            st.caption(f"... e mais {len(alertas) - 5} alertas")

        if not dados_lidar_encontrados:
            st.info("ğŸ›©ï¸ **Dados LiDAR:** Nenhum carregado (opcional)")

        # === RESUMO FINAL ===
        st.markdown("---")

        with st.expander("ğŸ¯ Resumo do Status Geral", expanded=True):
            # Verificar completude
            tem_inventario = hasattr(st.session_state,
                                     'dados_inventario') and st.session_state.dados_inventario is not None
            tem_cubagem = hasattr(st.session_state, 'dados_cubagem') and st.session_state.dados_cubagem is not None
            dados_basicos_ok = tem_inventario and tem_cubagem

            col1, col2, col3 = st.columns(3)

            with col1:
                st.subheader("ğŸ“Š Status Principal")
                if dados_basicos_ok:
                    st.success("ğŸ‰ **Dados principais completos!**")
                    st.caption("âœ… InventÃ¡rio e Cubagem carregados")
                    st.caption("ğŸš€ Sistema pronto para anÃ¡lises")
                else:
                    st.error("âŒ **Dados principais incompletos**")
                    if not tem_inventario:
                        st.caption("âŒ Falta: InventÃ¡rio")
                    if not tem_cubagem:
                        st.caption("âŒ Falta: Cubagem")

            with col2:
                st.subheader("ğŸ“ Dados Adicionais")
                extras = []
                if arquivos_espaciais_encontrados:
                    extras.append("ğŸ—ºï¸ Espaciais")
                if dados_lidar_encontrados:
                    extras.append("ğŸ›©ï¸ LiDAR")

                if extras:
                    st.info(f"âœ¨ **{len(extras)} tipo(s) extra(s)**")
                    for extra in extras:
                        st.caption(f"âœ… {extra}")
                else:
                    st.warning("ğŸ“­ **Nenhum dado adicional**")
                    st.caption("ğŸ’¡ Carregue LiDAR ou dados espaciais")

            with col3:
                st.subheader("ğŸš€ PrÃ³ximos Passos")
                if dados_basicos_ok:
                    try:
                        from config.configuracoes_globais import obter_configuracao_global
                        config_global = obter_configuracao_global()
                        configurado = config_global.get('configurado', False)

                        if not configurado:
                            st.warning("âš™ï¸ **Configure o sistema**")
                            st.caption("ğŸ“ VÃ¡ para Etapa 0")
                        else:
                            # Verificar etapas executadas
                            hip_ok = hasattr(st.session_state,
                                             'resultados_hipsometricos') and st.session_state.resultados_hipsometricos is not None
                            vol_ok = hasattr(st.session_state,
                                             'resultados_volumetricos') and st.session_state.resultados_volumetricos is not None
                            inv_ok = hasattr(st.session_state,
                                             'inventario_processado') and st.session_state.inventario_processado is not None

                            if not hip_ok:
                                st.info("ğŸŒ³ **Execute Etapa 1**")
                                st.caption("ğŸ“ Modelos HipsomÃ©tricos")
                            elif not vol_ok:
                                st.info("ğŸ“Š **Execute Etapa 2**")
                                st.caption("ğŸ“ Modelos VolumÃ©tricos")
                            elif not inv_ok:
                                st.info("ğŸ“ˆ **Execute Etapa 3**")
                                st.caption("ğŸ“ InventÃ¡rio Final")
                            else:
                                st.success("âœ… **Core completo!**")
                                if dados_lidar_encontrados:
                                    st.caption("ğŸ›©ï¸ LiDAR disponÃ­vel")
                                else:
                                    st.caption("ğŸ’¡ Carregue LiDAR")
                    except:
                        st.warning("âš™ï¸ **Configure primeiro**")
                        st.caption("ğŸ“ Etapa 0 obrigatÃ³ria")
                else:
                    st.error("ğŸ“ **Carregue dados**")
                    st.caption("ğŸ“ InventÃ¡rio + Cubagem")

            # InformaÃ§Ãµes de sessÃ£o
            st.markdown("---")
            st.markdown("**ğŸ’¾ InformaÃ§Ãµes da SessÃ£o:**")

            arquivos_na_sessao = []
            if tem_inventario:
                arquivos_na_sessao.append("ğŸ“‹ InventÃ¡rio")
            if tem_cubagem:
                arquivos_na_sessao.append("ğŸ“ Cubagem")
            if dados_lidar_encontrados:
                arquivos_na_sessao.append("ğŸ›©ï¸ LiDAR")
            if arquivos_espaciais_encontrados:
                arquivos_na_sessao.append("ğŸ—ºï¸ Espaciais")

            # Verificar resultados processados
            resultados_na_sessao = []
            if hasattr(st.session_state,
                       'resultados_hipsometricos') and st.session_state.resultados_hipsometricos is not None:
                resultados_na_sessao.append("ğŸŒ³ HipsomÃ©tricos")
            if hasattr(st.session_state,
                       'resultados_volumetricos') and st.session_state.resultados_volumetricos is not None:
                resultados_na_sessao.append("ğŸ“Š VolumÃ©tricos")
            if hasattr(st.session_state,
                       'inventario_processado') and st.session_state.inventario_processado is not None:
                resultados_na_sessao.append("ğŸ“ˆ InventÃ¡rio Final")

            if arquivos_na_sessao:
                st.success("**Arquivos persistidos:** " + " â€¢ ".join(arquivos_na_sessao))

            if resultados_na_sessao:
                st.info("**Resultados salvos:** " + " â€¢ ".join(resultados_na_sessao))

            if not arquivos_na_sessao and not resultados_na_sessao:
                st.warning("ğŸ“­ Nenhum dado na sessÃ£o")

            st.caption("ğŸ’¡ **Dica:** Dados permanecem ao navegar entre pÃ¡ginas, mas sÃ£o perdidos ao fechar o navegador")

    except Exception as e:
        st.error(f"âŒ Erro ao mostrar preview dos dados: {e}")
        with st.expander("ğŸ” Detalhes do erro"):
            st.code(traceback.format_exc())


def mostrar_preview_dados_lidar():
    """Mostra preview especÃ­fico dos dados LiDAR - VERSÃƒO ORIGINAL"""
    dados_lidar_encontrados = False

    # Verificar arquivo LAS/LAZ
    if hasattr(st.session_state, 'arquivo_las') and st.session_state.arquivo_las is not None:
        st.subheader("ğŸ›©ï¸ Arquivo LAS/LAZ Carregado")

        arquivo_las = st.session_state.arquivo_las

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Arquivo", "LAS/LAZ")
        with col2:
            try:
                nome = getattr(arquivo_las, 'name', 'arquivo.las')
                st.metric("Nome", nome[:20] + "..." if len(nome) > 20 else nome)
            except:
                st.metric("Nome", "N/A")
        with col3:
            try:
                tamanho_mb = getattr(arquivo_las, 'size', 0) / (1024 * 1024)
                st.metric("Tamanho", f"{tamanho_mb:.1f} MB")
            except:
                st.metric("Tamanho", "N/A")
        with col4:
            # Verificar se jÃ¡ foi processado
            processado = hasattr(st.session_state, 'dados_lidar_las') and st.session_state.dados_lidar_las is not None
            st.metric("Status", "âœ… Processado" if processado else "â³ Pendente")

        dados_lidar_encontrados = True

    # Verificar dados LAS processados
    if hasattr(st.session_state, 'dados_lidar_las') and st.session_state.dados_lidar_las is not None:
        st.subheader("ğŸ“Š Dados LAS Processados")

        dados_las = st.session_state.dados_lidar_las

        if 'df_metricas' in dados_las:
            df_metricas = dados_las['df_metricas']

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Parcelas", len(df_metricas))
            with col2:
                try:
                    altura_media = df_metricas['altura_media'].mean()
                    st.metric("Altura MÃ©dia", f"{altura_media:.1f} m")
                except:
                    st.metric("Altura MÃ©dia", "N/A")
            with col3:
                try:
                    pontos_total = df_metricas['n_pontos'].sum()
                    st.metric("Total Pontos", f"{pontos_total:,}")
                except:
                    st.metric("Total Pontos", "N/A")
            with col4:
                try:
                    cobertura_media = df_metricas['cobertura'].mean()
                    st.metric("Cobertura", f"{cobertura_media:.1f}%")
                except:
                    st.metric("Cobertura", "N/A")

            if st.checkbox("ğŸ‘€ Preview MÃ©tricas LAS"):
                st.dataframe(df_metricas.head(), use_container_width=True)

        dados_lidar_encontrados = True

    # Verificar mÃ©tricas LiDAR carregadas
    if hasattr(st.session_state, 'arquivo_metricas_lidar') and st.session_state.arquivo_metricas_lidar is not None:
        st.subheader("ğŸ“Š MÃ©tricas LiDAR Carregadas")

        arquivo_metricas = st.session_state.arquivo_metricas_lidar

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Tipo", "MÃ©tricas CSV/Excel")
        with col2:
            try:
                nome = getattr(arquivo_metricas, 'name', 'metricas.csv')
                st.metric("Arquivo", nome[:20] + "..." if len(nome) > 20 else nome)
            except:
                st.metric("Arquivo", "N/A")
        with col3:
            # Verificar se foi integrado
            integrado = hasattr(st.session_state, 'dados_lidar') and st.session_state.dados_lidar is not None
            st.metric("Status", "âœ… Integrado" if integrado else "â³ Pendente")
        with col4:
            st.metric("Origem", "PrÃ©-processado")

        dados_lidar_encontrados = True

    # Verificar dados LiDAR integrados
    if hasattr(st.session_state, 'dados_lidar') and st.session_state.dados_lidar is not None:
        st.subheader("ğŸ”— Dados LiDAR Integrados")

        dados_lidar = st.session_state.dados_lidar

        if 'stats_comparacao' in dados_lidar and dados_lidar['stats_comparacao'] is not None:
            stats = dados_lidar['stats_comparacao']

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                correlacao = stats.get('correlacao', 0)
                st.metric("CorrelaÃ§Ã£o", f"{correlacao:.3f}")
            with col2:
                r2 = stats.get('r2', 0)
                st.metric("RÂ²", f"{r2:.3f}")
            with col3:
                rmse = stats.get('rmse', 0)
                st.metric("RMSE", f"{rmse:.2f} m")
            with col4:
                n_parcelas = stats.get('n_parcelas', 0)
                st.metric("Parcelas", n_parcelas)

        # Mostrar alertas se houver
        if 'alertas' in dados_lidar and dados_lidar['alertas']:
            st.info(f"âš ï¸ {len(dados_lidar['alertas'])} alertas gerados na integraÃ§Ã£o")

        dados_lidar_encontrados = True

    # Mostrar botÃ£o de acesso ao LiDAR se hÃ¡ dados
    if dados_lidar_encontrados:
        st.info("ğŸ›©ï¸ **Dados LiDAR disponÃ­veis!** Acesse a Etapa 4 para anÃ¡lise completa.")


def mostrar_status_sistema():
    """Mostra status geral do sistema incluindo LiDAR"""
    st.subheader("ğŸ”§ Status do Sistema")

    try:
        # Obter status completo do sistema
        status = obter_status_sistema_completo()

        # === LINHA 1: DADOS PRINCIPAIS ===
        col1, col2, col3, col4, col5 = st.columns(5)

        with col1:
            if status['dados_inventario'] and status['dados_cubagem']:
                st.success("âœ… **Dados NecessÃ¡rios**\nCarregados")
            elif status['dados_inventario'] or status['dados_cubagem']:
                st.warning("âš ï¸ **Dados NecessÃ¡rios**\nIncompletos")
            else:
                st.error("âŒ **Dados**\nFaltantes")

        with col2:
            if status['configurado']:
                st.success("âœ… **ConfiguraÃ§Ã£o**\nOK")
            else:
                st.error("âŒ **ConfiguraÃ§Ã£o**\nNecessÃ¡ria")

        with col3:
            if status['hip_executado']:
                st.success("âœ… **HipsomÃ©tricos**\nConcluÃ­da")
            else:
                st.info("â³ **HipsomÃ©tricos**\nPendente")

        with col4:
            if status['vol_executado']:
                st.success("âœ… **VolumÃ©tricos**\nConcluÃ­da")
            else:
                st.info("â³ **VolumÃ©tricos**\nPendente")

        with col5:
            if status['inv_executado']:
                st.success("âœ… **InventÃ¡rio**\nConcluÃ­da")
            else:
                st.info("â³ **InventÃ¡rio**\nPendente")

        # === LINHA 2: DADOS LIDAR ===
        st.markdown("#### ğŸ›©ï¸ Status LiDAR")
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            if status['arquivo_las_disponivel']:
                st.success("âœ… **Arquivo LAS**\nDisponÃ­vel")
            else:
                st.info("â³ **Arquivo LAS**\nNÃ£o carregado")

        with col2:
            if status['metricas_lidar_disponivel']:
                st.success("âœ… **MÃ©tricas**\nDisponÃ­veis")
            else:
                st.info("â³ **MÃ©tricas**\nNÃ£o carregadas")

        with col3:
            if status['dados_lidar_processados']:
                st.success("âœ… **LAS Processado**\nConcluÃ­do")
            elif status['arquivo_las_disponivel']:
                st.warning("âš ï¸ **LAS Processado**\nPendente")
            else:
                st.info("â³ **LAS Processado**\nSem arquivo")

        with col4:
            if status['dados_lidar_integrados']:
                st.success("âœ… **LiDAR Integrado**\nConcluÃ­do")
            elif status['metricas_lidar_disponivel'] or status['dados_lidar_processados']:
                st.warning("âš ï¸ **LiDAR Integrado**\nPendente")
            else:
                st.info("â³ **LiDAR Integrado**\nSem dados")

        # Progresso geral
        st.markdown("#### ğŸ“Š Progresso Geral")

        # Barra de progresso principal (etapas obrigatÃ³rias)
        st.progress(status['progresso_total'], text=f"Etapas Principais: {status['progresso_total'] * 100:.0f}%")

        # Barra de progresso completo (incluindo LiDAR)
        if status['progresso_completo'] > status['progresso_total']:
            st.progress(status['progresso_completo'],
                        text=f"Progresso Completo: {status['progresso_completo'] * 100:.0f}% (inclui LiDAR)")

    except Exception as e:
        st.error(f"âŒ Erro ao mostrar status do sistema: {e}")


def mostrar_info_persistencia():
    """Mostra informaÃ§Ãµes sobre persistÃªncia na sessÃ£o"""
    try:
        with st.expander("ğŸ’¾ InformaÃ§Ãµes de PersistÃªncia"):
            st.markdown("""
            **ğŸ”„ Dados Persistentes na SessÃ£o:**

            **âœ… Permanecem ao navegar entre pÃ¡ginas:**
            - ğŸ“‹ Dados de inventÃ¡rio processados
            - ğŸ“ Dados de cubagem processados
            - ğŸ›©ï¸ Arquivos LAS/LAZ carregados
            - ğŸ“Š MÃ©tricas LiDAR carregadas
            - ğŸ—ºï¸ Shapefiles carregados
            - ğŸ“ Coordenadas carregadas
            - âš™ï¸ ConfiguraÃ§Ãµes do sistema
            - ğŸ“ˆ Resultados das anÃ¡lises

            **âŒ SÃ£o perdidos ao:**
            - Fechar o navegador
            - Recarregar a pÃ¡gina (F5)
            - Limpar cache do sistema
            - Timeout da sessÃ£o (inatividade longa)

            **ğŸ’¡ Dica:** FaÃ§a download dos resultados importantes!
            """)

            # Mostrar arquivos atualmente persistidos
            st.markdown("**ğŸ“‚ Status Atual da SessÃ£o:**")

            arquivos_persistidos = []

            # Verificar cada tipo de dado
            if hasattr(st.session_state, 'dados_inventario') and st.session_state.dados_inventario is not None:
                arquivos_persistidos.append("âœ… InventÃ¡rio processado")

            if hasattr(st.session_state, 'dados_cubagem') and st.session_state.dados_cubagem is not None:
                arquivos_persistidos.append("âœ… Cubagem processada")

            if hasattr(st.session_state, 'arquivo_las') and st.session_state.arquivo_las is not None:
                arquivos_persistidos.append("âœ… Arquivo LAS/LAZ")

            if hasattr(st.session_state,
                       'arquivo_metricas_lidar') and st.session_state.arquivo_metricas_lidar is not None:
                arquivos_persistidos.append("âœ… MÃ©tricas LiDAR")

            if hasattr(st.session_state, 'arquivo_shapefile') and st.session_state.arquivo_shapefile is not None:
                arquivos_persistidos.append("âœ… Shapefile")

            if hasattr(st.session_state, 'arquivo_coordenadas') and st.session_state.arquivo_coordenadas is not None:
                arquivos_persistidos.append("âœ… Coordenadas")

            # Verificar resultados
            resultados = ['resultados_hipsometricos', 'resultados_volumetricos', 'inventario_processado',
                          'dados_lidar_las', 'dados_lidar']

            for resultado in resultados:
                if hasattr(st.session_state, resultado) and getattr(st.session_state, resultado) is not None:
                    nome_amigavel = {
                        'resultados_hipsometricos': 'Modelos HipsomÃ©tricos',
                        'resultados_volumetricos': 'Modelos VolumÃ©tricos',
                        'inventario_processado': 'InventÃ¡rio Final',
                        'dados_lidar_las': 'Processamento LAS',
                        'dados_lidar': 'IntegraÃ§Ã£o LiDAR'
                    }
                    arquivos_persistidos.append(f"âœ… {nome_amigavel.get(resultado, resultado)}")

            if arquivos_persistidos:
                for arquivo in arquivos_persistidos:
                    st.success(arquivo)
            else:
                st.info("ğŸ“­ Nenhum dado persistido na sessÃ£o")

    except Exception as e:
        st.error(f"âŒ Erro ao mostrar informaÃ§Ãµes de persistÃªncia: {e}")


def main():
    """FunÃ§Ã£o principal da aplicaÃ§Ã£o - VERSÃƒO COMPLETA COM LAS/LAZ E PREVIEW EXPANDIDO"""
    try:
        # Inicializar configuraÃ§Ãµes globais
        inicializar_configuracoes_globais()

        # Criar cabeÃ§alho
        criar_cabecalho_greenvista("PÃ¡gina Principal")

        # Criar sidebar com uploads - VERSÃƒO COMPLETA
        arquivos = criar_sidebar_melhorada()

        st.markdown('''
        O sistema LiDAR do **GreenVista** representa uma soluÃ§Ã£o completa e robusta para integraÃ§Ã£o de dados 
        de sensoriamento remoto com inventÃ¡rios florestais tradicionais. Combina facilidade de uso com
         capacidades tÃ©cnicas avanÃ§adas, oferecendo desde processamento bÃ¡sico atÃ© anÃ¡lises estruturais 
         sofisticadas.
         **Ideal para:** Empresas florestais que desejam modernizar seus inventÃ¡rios com tecnologia
          LiDAR sem complexidade tÃ©cnica excessiva.
            
        '''  )

        with st.expander("ğŸ›©ï¸ Saiba mais sobre a anÃ¡lise do sistema de processamento LiDAR do **GreenVista**"):
            st.markdown("""

            O sistema **GreenVista** integra processamento de dados LiDAR para anÃ¡lise florestal, oferecendo duas abordagens principais:
            
            1. **Processamento Direto LAS/LAZ** - Arquivos brutos do sensor
            2. **IntegraÃ§Ã£o de MÃ©tricas** - CSV/Excel prÃ©-processados
            
            ## ğŸ—ï¸ Arquitetura do Sistema
            
            ### Componentes Principais
            
            #### 1. **ConfiguraÃ§Ã£o Central**
            - **ConfiguraÃ§Ãµes por EspÃ©cie**: Eucalipto, Pinus, Nativa
            - **Perfis de Processamento**: RÃ¡pido, Balanceado, Preciso, MemÃ³ria Limitada
            - **ValidaÃ§Ã£o de ParÃ¢metros**: Limites automÃ¡ticos para mÃ©tricas
            - **OtimizaÃ§Ã£o DinÃ¢mica**: Ajuste baseado no tamanho do arquivo
                    
            #### 2. **Processador LAS Integrado** 
            - **GestÃ£o de MemÃ³ria**: Processamento em chunks otimizado
            - **ValidaÃ§Ã£o AutomÃ¡tica**: VerificaÃ§Ã£o de estrutura e qualidade
            - **Interface Streamlit**: Feedback em tempo real
            - **MÃ©tricas Abrangentes**: 15+ mÃ©tricas estruturais calculadas
            
            ### Funcionalidades AvanÃ§adas
            
            #### **Processamento Inteligente**
            - âœ… **Chunks Adaptativos**: 100K-2M pontos por chunk baseado na memÃ³ria
            - âœ… **ValidaÃ§Ã£o Estrutural**: VerificaÃ§Ã£o de coordenadas, alturas e geometria  
            - âœ… **OtimizaÃ§Ã£o de MemÃ³ria**: Garbage collection automÃ¡tico
            - âœ… **Progress Tracking**: Monitoramento em tempo real
            
            #### **MÃ©tricas Calculadas**
            
            #### **IntegraÃ§Ã£o com InventÃ¡rio**
            - ğŸ¯ **Parcelas Georreferenciadas**: Usa coordenadas X,Y quando disponÃ­veis
            - ğŸ¯ **Grid AutomÃ¡tico**: Cria malha quando coordenadas nÃ£o existem
            - ğŸ¯ **ValidaÃ§Ã£o Cruzada**: ComparaÃ§Ã£o campo vs LiDAR
            - ğŸ¯ **CalibraÃ§Ã£o de Modelos**: Ajuste hipsomÃ©trico com dados LiDAR
            
            ## ğŸ”„ Fluxo de Trabalho
            
            ### CenÃ¡rio 1: Processamento LAS/LAZ
            ```mermaid
           
                A[Upload Arquivo LAS] --> B{Validar Estrutura}
                B -->|âœ… VÃ¡lido| C[Definir Parcelas]
                B -->|âŒ InvÃ¡lido| D[Erro/InstruÃ§Ãµes]
                C --> E{Tamanho Arquivo}
                E -->|Grande| F[Processamento Chunks]
                E -->|Pequeno| G[Processamento Direto]
                F --> H[Calcular MÃ©tricas]
                G --> H
                H --> I[Integrar com InventÃ¡rio]
                I --> J[AnÃ¡lise Comparativa]
            ```
            
            ### CenÃ¡rio 2: MÃ©tricas PrÃ©-processadas
            ```mermaid
    
                A[Upload CSV/Excel] --> B[Validar Colunas]
                B --> C[Padronizar Nomes]
                C --> D[Limpar Dados]
                D --> E[Integrar com InventÃ¡rio]
                E --> F[ComparaÃ§Ã£o Campo-LiDAR]
                F --> G[Gerar Alertas]
            ```
            
            ## ğŸ“Š Interface de UsuÃ¡rio
            
            ### PÃ¡gina Principal
            
            #### **Recursos de Interface**
            - ğŸ¨ **Identidade Visual**: CabeÃ§alho GreenVista consistente
            - ğŸ“± **Layout Responsivo**: Tabs dinÃ¢micas baseadas em dados disponÃ­veis
            - ğŸ”„ **Estado Persistente**: Dados salvos entre sessÃµes
            - ğŸ“‹ **Feedback Contextual**: Mensagens especÃ­ficas por situaÃ§Ã£o
            
            #### **Controle de Fluxo Inteligente**
            
            ## ğŸ›¡ï¸ Robustez e Confiabilidade
            
            ### ValidaÃ§Ã£o MultinÃ­vel
            
            #### **NÃ­vel 1: Arquivo**
            - Formato (.las/.laz)
            - Tamanho (mÃ¡x 500MB)
            - Estrutura (coordenadas XYZ)
            
            #### **NÃ­vel 2: Dados**
            - NÃºmero de pontos (mÃ¡x 50M)
            - Alturas realÃ­sticas (0.1-150m)
            - Geometria vÃ¡lida
            
            #### **NÃ­vel 3: MÃ©tricas**
            - Valores dentro de limites esperados
            - DetecÃ§Ã£o de outliers (IQR 3Ã—)
            - ConsistÃªncia entre parcelas
            
            ### GestÃ£o de Erros
            
            ## ğŸ”§ Recursos TÃ©cnicos AvanÃ§ados
            
            ### OtimizaÃ§Ã£o de Performance
            
            #### **Processamento em Chunks**
            - **Tamanho Adaptativo**: 100K-2M pontos baseado na memÃ³ria disponÃ­vel
            - **GestÃ£o de MemÃ³ria**: Limpeza automÃ¡tica a cada 3 chunks
            - **Progress Tracking**: Feedback visual em tempo real
            
            #### **Algoritmos Otimizados**
            
            ### IntegraÃ§Ã£o Inteligente
            
            #### **DetecÃ§Ã£o AutomÃ¡tica de Parcelas**
            1. **Com Coordenadas**: Parcelas circulares georreferenciadas
            2. **Sem Coordenadas**: Grid estimado baseado na distribuiÃ§Ã£o
            3. **Grid AutomÃ¡tico**: CÃ©lulas 20Ã—20m para anÃ¡lise exploratÃ³ria
            
            #### **CalibraÃ§Ã£o de Modelos**
            
            ## ğŸ“ˆ AnÃ¡lises DisponÃ­veis
            
            ### 1. **ComparaÃ§Ã£o Campo vs LiDAR**
            - CorrelaÃ§Ã£o e RÂ²
            - RMSE e bias sistemÃ¡tico
            - DetecÃ§Ã£o de outliers
            - GrÃ¡ficos de dispersÃ£o e resÃ­duos
            
            ### 2. **AnÃ¡lise Estrutural**
            - DistribuiÃ§Ã£o de alturas por talhÃ£o
            - MÃ©tricas de complexidade estrutural
            - Ãndices de diversidade (Shannon)
            - Cobertura e densidade do dossel
            
            ### 3. **CalibraÃ§Ã£o de Modelos**
            - Ajuste de modelos hipsomÃ©tricos
            - ValidaÃ§Ã£o cruzada
            - ComparaÃ§Ã£o prÃ©/pÃ³s calibraÃ§Ã£o
            - MÃ©tricas de melhoria
            
            ### 4. **Alertas AutomÃ¡ticos**
            - CorrelaÃ§Ã£o baixa (<0.6)
            - Outliers excessivos (>10%)
            - Bias sistemÃ¡tico (>2m)
            - Cobertura insuficiente (<30%)
            
            ## ğŸ’¾ Sistema de PersistÃªncia
            
            ### Gerenciamento de Estado
            
            ### Downloads DisponÃ­veis
            - ğŸ“Š **CSV/Excel**: MÃ©tricas completas
            - ğŸ“„ **RelatÃ³rio MD**: AnÃ¡lise detalhada  
            - ğŸ“ˆ **MÃ©tricas JSON**: ValidaÃ§Ã£o tÃ©cnica
            - ğŸ¯ **Outliers CSV**: Parcelas problemÃ¡ticas
            
            ## ğŸš€ Vantagens Competitivas
            
            ### âœ… **Facilidade de Uso**
            - Interface intuitiva sem conhecimento tÃ©cnico
            - Processamento automÃ¡tico com configuraÃ§Ã£o mÃ­nima
            - Feedback visual constante
            
            ### âœ… **Flexibilidade**
            - Suporte a LAS/LAZ e mÃ©tricas prÃ©-processadas
            - ConfiguraÃ§Ãµes por espÃ©cie florestal
            - IntegraÃ§Ã£o com qualquer inventÃ¡rio
            
            ### âœ… **Robustez**
            - ValidaÃ§Ã£o multinÃ­vel
            - GestÃ£o inteligente de memÃ³ria
            - RecuperaÃ§Ã£o de erros graceful
            
            ### âœ… **Completude**
            - 15+ mÃ©tricas estruturais
            - AnÃ¡lises comparativas automÃ¡ticas
            - RelatÃ³rios prontos para uso
            
            ## ğŸ¯ Casos de Uso TÃ­picos
            
            ### 1. **ValidaÃ§Ã£o de InventÃ¡rio**
            Empresa quer verificar se mediÃ§Ãµes de campo sÃ£o consistentes com dados LiDAR
            
            ### 2. **CalibraÃ§Ã£o de Modelos**
            Melhorar modelos hipsomÃ©tricos usando dados LiDAR como referÃªncia
            
            ### 3. **Mapeamento de Estrutura**
            Analisar heterogeneidade estrutural em diferentes talhÃµes
            
            ### 4. **DetecÃ§Ã£o de Problemas**
            Identificar parcelas com mediÃ§Ãµes inconsistentes ou problemÃ¡ticas
                       
             """)

        # === SEÃ‡ÃƒO PRINCIPAL DA PÃGINA ===
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸ“Š Status do Sistema",
            "ğŸ“‹ InstruÃ§Ãµes",
            "âš ï¸ Alertas",
            "ğŸ‘¨ğŸ»â€ğŸ’» Quem somos"
        ])

        with tab1:
            mostrar_status_sistema()
            st.markdown("---")
            mostrar_preview_inteligente()
            # === INFORMAÃ‡Ã•ES DE PERSISTÃŠNCIA ===
            mostrar_info_persistencia()

        with tab2:
            criar_secao_instrucoes()

        with tab3:
            mostrar_alertas_sistema()

        with tab4:
            mostrar_empresa()

        # NavegaÃ§Ã£o rÃ¡pida
        st.markdown("---")
        criar_navegacao_rapida_botoes()


    except Exception as e:
        st.error("âŒ Erro crÃ­tico na aplicaÃ§Ã£o principal")

        with st.expander("ğŸ” Detalhes do Erro CrÃ­tico"):
            st.code(f"Erro: {str(e)}")
            st.code(traceback.format_exc())

        # Oferecer reset do sistema
        st.warning("ğŸ”„ **SoluÃ§Ã£o:** Tente recarregar a pÃ¡gina ou limpar o cache")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ Recarregar PÃ¡gina", type="primary"):
                st.rerun()

        with col2:
            if st.button("ğŸ—‘ï¸ Limpar Cache", type="secondary"):
                # Limpar session_state
                keys_para_limpar = [k for k in st.session_state.keys()
                                    if not k.startswith('FormSubmitter')]
                for key in keys_para_limpar:
                    try:
                        del st.session_state[key]
                    except:
                        pass
                st.success("âœ… Cache limpo! Recarregando...")
                st.rerun()


if __name__ == "__main__":
    main()