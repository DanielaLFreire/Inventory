# processors/lidar.py
'''
Processamento e integra√ß√£o de dados LiDAR com invent√°rio florestal
Integra m√©tricas extra√≠das do script R com dados de campo
'''

import pandas as pd
import numpy as np
import streamlit as st
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import cross_val_score, KFold
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
from config.config import (
    COLUNAS_LIDAR_OBRIGATORIAS,
    NOMES_ALTERNATIVOS_LIDAR,
    CONFIGURACOES_LIDAR,
    THRESHOLDS_ALERTAS_LIDAR,
    CLASSIFICACAO_CALIBRACAO_LIDAR,
    CORES_LIDAR
)


def processar_dados_lidar(arquivo_lidar):
    """
    Processa arquivo de m√©tricas LiDAR gerado pelo script R

    Args:
        arquivo_lidar: Arquivo CSV/Excel com m√©tricas das parcelas

    Returns:
        DataFrame com m√©tricas LiDAR processadas ou None se erro
    """
    try:
        from utils.arquivo_handler import carregar_arquivo

        # Carregar arquivo
        df_lidar = carregar_arquivo(arquivo_lidar)
        if df_lidar is None:
            st.error("‚ùå N√£o foi poss√≠vel carregar arquivo LiDAR")
            return None

        # Validar estrutura b√°sica
        validacao = validar_estrutura_lidar(df_lidar)
        if not validacao['valido']:
            st.error("‚ùå Estrutura de dados LiDAR inv√°lida:")
            for erro in validacao['erros']:
                st.error(f"‚Ä¢ {erro}")
            return None

        # Padronizar nomes das colunas
        df_lidar = padronizar_colunas_lidar(df_lidar)

        # Limpar e validar dados
        df_lidar = limpar_dados_lidar(df_lidar)

        # Calcular m√©tricas derivadas
        df_lidar = calcular_metricas_derivadas_lidar(df_lidar)

        st.success(f"‚úÖ Dados LiDAR processados: {len(df_lidar)} parcelas")

        return df_lidar

    except Exception as e:
        st.error(f"‚ùå Erro ao processar dados LiDAR: {e}")
        return None


def validar_estrutura_lidar(df_lidar):
    """
    Valida estrutura b√°sica dos dados LiDAR

    Args:
        df_lidar: DataFrame com dados LiDAR

    Returns:
        dict: Resultado da valida√ß√£o
    """
    validacao = {'valido': True, 'erros': [], 'alertas': []}

    # Verificar se DataFrame n√£o est√° vazio
    if len(df_lidar) == 0:
        validacao['erros'].append("Arquivo LiDAR vazio")
        validacao['valido'] = False
        return validacao

    # Verificar colunas obrigat√≥rias
    colunas_faltantes = []
    for col in COLUNAS_LIDAR_OBRIGATORIAS:
        if col not in df_lidar.columns:
            # Tentar encontrar equivalentes
            encontrada = False
            for col_orig in df_lidar.columns:
                if col.lower() in col_orig.lower():
                    encontrada = True
                    break
            if not encontrada:
                colunas_faltantes.append(col)

    if colunas_faltantes:
        validacao['erros'].append(f"Colunas obrigat√≥rias faltantes: {colunas_faltantes}")
        validacao['valido'] = False

    # Verificar se h√° pelo menos uma m√©trica LiDAR
    metricas_encontradas = 0
    for metrica_padrao, aliases in NOMES_ALTERNATIVOS_LIDAR.items():
        for alias in aliases:
            if alias in df_lidar.columns:
                metricas_encontradas += 1
                break

    if metricas_encontradas == 0:
        validacao['erros'].append("Nenhuma m√©trica LiDAR reconhecida encontrada")
        validacao['valido'] = False
    elif metricas_encontradas < 3:
        validacao['alertas'].append(f"Poucas m√©tricas LiDAR encontradas: {metricas_encontradas}")

    return validacao


def padronizar_colunas_lidar(df_lidar):
    """
    Padroniza nomes das colunas baseado nos aliases conhecidos

    Args:
        df_lidar: DataFrame com dados LiDAR

    Returns:
        DataFrame com colunas padronizadas
    """
    df_padronizado = df_lidar.copy()

    # Mapear colunas para nomes padr√£o
    mapeamento = {}

    for nome_padrao, aliases in NOMES_ALTERNATIVOS_LIDAR.items():
        for alias in aliases:
            if alias in df_padronizado.columns:
                mapeamento[alias] = nome_padrao
                break

    # Renomear colunas
    df_padronizado = df_padronizado.rename(columns=mapeamento)

    # Garantir que talhao e parcela sejam inteiros
    if 'talhao' in df_padronizado.columns:
        df_padronizado['talhao'] = pd.to_numeric(df_padronizado['talhao'], errors='coerce').astype('Int64')
    if 'parcela' in df_padronizado.columns:
        df_padronizado['parcela'] = pd.to_numeric(df_padronizado['parcela'], errors='coerce').astype('Int64')

    return df_padronizado


def limpar_dados_lidar(df_lidar):
    """
    Limpa e valida dados LiDAR

    Args:
        df_lidar: DataFrame com dados LiDAR

    Returns:
        DataFrame limpo
    """
    df_limpo = df_lidar.copy()

    # Remover linhas sem identifica√ß√£o de talhao/parcela
    df_limpo = df_limpo.dropna(subset=['talhao', 'parcela'])

    # Converter m√©tricas para num√©rico
    colunas_numericas = [col for col in df_limpo.columns
                         if col not in ['talhao', 'parcela'] and
                         col in NOMES_ALTERNATIVOS_LIDAR.keys()]

    for col in colunas_numericas:
        df_limpo[col] = pd.to_numeric(df_limpo[col], errors='coerce')

    # Aplicar filtros de qualidade
    limites = CONFIGURACOES_LIDAR['limites_validacao']

    # Filtrar alturas irreais se altura_media dispon√≠vel
    if 'altura_media' in df_limpo.columns:
        mask_altura = (df_limpo['altura_media'] >= limites['altura_min']) & \
                      (df_limpo['altura_media'] <= limites['altura_max'])
        df_limpo = df_limpo[mask_altura]

    # Remover outliers extremos usando IQR
    for col in colunas_numericas:
        if col in df_limpo.columns:
            Q1 = df_limpo[col].quantile(0.25)
            Q3 = df_limpo[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 3 * IQR  # 3*IQR para ser menos restritivo
            upper_bound = Q3 + 3 * IQR

            df_limpo = df_limpo[(df_limpo[col] >= lower_bound) & (df_limpo[col] <= upper_bound)]

    return df_limpo


def calcular_metricas_derivadas_lidar(df_lidar):
    """
    Calcula m√©tricas derivadas a partir das m√©tricas b√°sicas LiDAR

    Args:
        df_lidar: DataFrame com m√©tricas b√°sicas

    Returns:
        DataFrame com m√©tricas derivadas adicionais
    """
    df_derivado = df_lidar.copy()

    # √çndice de heterogeneidade vertical (se altura_media e desvio_altura dispon√≠veis)
    if 'altura_media' in df_derivado.columns and 'desvio_altura' in df_derivado.columns:
        df_derivado['heterogeneidade_vertical'] = df_derivado['desvio_altura'] / df_derivado['altura_media']
        df_derivado['heterogeneidade_vertical'] = df_derivado['heterogeneidade_vertical'].fillna(0)

    # √çndice de ocupa√ß√£o vertical (se cobertura e densidade dispon√≠veis)
    if 'cobertura' in df_derivado.columns and 'densidade' in df_derivado.columns:
        df_derivado['ocupacao_vertical'] = df_derivado['densidade'] / df_derivado['cobertura']
        df_derivado['ocupacao_vertical'] = df_derivado['ocupacao_vertical'].fillna(0)

    # Raz√£o altura m√°xima/m√©dia (indicador de domin√¢ncia)
    if 'altura_maxima' in df_derivado.columns and 'altura_media' in df_derivado.columns:
        df_derivado['razao_max_media'] = df_derivado['altura_maxima'] / df_derivado['altura_media']
        df_derivado['razao_max_media'] = df_derivado['razao_max_media'].fillna(1)

    # Classificar complexidade estrutural
    if 'complexidade' in df_derivado.columns:
        df_derivado['classe_complexidade'] = pd.cut(
            df_derivado['complexidade'],
            bins=[-np.inf, 0.2, 0.5, 0.8, np.inf],
            labels=['Baixa', 'M√©dia', 'Alta', 'Muito Alta']
        )

    return df_derivado


def integrar_dados_lidar_inventario(df_inventario, df_lidar):
    """
    Integra dados LiDAR com dados do invent√°rio florestal

    Args:
        df_inventario: DataFrame do invent√°rio
        df_lidar: DataFrame com m√©tricas LiDAR

    Returns:
        DataFrame integrado
    """
    try:
        # Fazer merge por talhao e parcela
        df_integrado = df_inventario.merge(
            df_lidar,
            on=['talhao', 'parcela'],
            how='left',
            suffixes=('', '_lidar')
        )

        # Verificar cobertura da integra√ß√£o
        parcelas_com_lidar = df_integrado['altura_media'].notna().sum()
        parcelas_total = len(df_integrado)
        cobertura_percentual = (parcelas_com_lidar / parcelas_total) * 100

        st.info(f"üìä Integra√ß√£o LiDAR: {parcelas_com_lidar}/{parcelas_total} parcelas ({cobertura_percentual:.1f}%)")

        if cobertura_percentual < 50:
            st.warning("‚ö†Ô∏è Baixa cobertura LiDAR - verifique compatibilidade dos dados")

        return df_integrado

    except Exception as e:
        st.error(f"‚ùå Erro na integra√ß√£o: {e}")
        return df_inventario


def comparar_alturas_campo_lidar(df_integrado):
    """
    Compara alturas medidas em campo com alturas LiDAR

    Args:
        df_integrado: DataFrame com dados integrados

    Returns:
        dict: Estat√≠sticas da compara√ß√£o
    """
    # Filtrar apenas registros com ambas as medi√ß√µes
    mask_validas = df_integrado['H_m'].notna() & df_integrado['altura_media'].notna()
    df_comparacao = df_integrado[mask_validas].copy()

    if len(df_comparacao) == 0:
        st.warning("‚ö†Ô∏è Nenhuma parcela com dados de altura de campo e LiDAR")
        return None

    # Calcular estat√≠sticas
    altura_campo = df_comparacao['H_m']
    altura_lidar = df_comparacao['altura_media']

    # Diferen√ßas
    diferenca = altura_campo - altura_lidar
    diferenca_abs = np.abs(diferenca)
    diferenca_percentual = (diferenca / altura_lidar) * 100

    # Correla√ß√£o
    correlacao = altura_campo.corr(altura_lidar)

    # Regress√£o linear
    X = altura_lidar.values.reshape(-1, 1)
    y = altura_campo.values

    modelo_reg = LinearRegression()
    modelo_reg.fit(X, y)

    y_pred = modelo_reg.predict(X)
    r2 = r2_score(y, y_pred)
    rmse = np.sqrt(mean_squared_error(y, y_pred))

    # Estat√≠sticas da compara√ß√£o
    stats_comparacao = {
        'n_parcelas': len(df_comparacao),
        'correlacao': correlacao,
        'r2': r2,
        'rmse': rmse,
        'diferenca_media': diferenca.mean(),
        'diferenca_std': diferenca.std(),
        'diferenca_abs_media': diferenca_abs.mean(),
        'diferenca_percentual_media': diferenca_percentual.mean(),
        'coeficiente_angular': modelo_reg.coef_[0],
        'intercepto': modelo_reg.intercept_,
        'dados_comparacao': df_comparacao,
        'outliers': detectar_outliers_comparacao(df_comparacao)
    }

    return stats_comparacao


def detectar_outliers_comparacao(df_comparacao):
    """
    Detecta outliers na compara√ß√£o campo vs LiDAR

    Args:
        df_comparacao: DataFrame com dados para compara√ß√£o

    Returns:
        DataFrame com outliers identificados
    """
    diferenca_abs = np.abs(df_comparacao['H_m'] - df_comparacao['altura_media'])
    threshold = THRESHOLDS_ALERTAS_LIDAR['diferenca_altura_critica']

    outliers = df_comparacao[diferenca_abs > threshold].copy()
    outliers['diferenca_absoluta'] = diferenca_abs[diferenca_abs > threshold]

    return outliers


def calibrar_modelo_hipsometrico_com_lidar(df_integrado, modelo_original):
    """
    Calibra modelo hipsom√©trico usando dados LiDAR como refer√™ncia

    Args:
        df_integrado: DataFrame com dados integrados
        modelo_original: Modelo hipsom√©trico original

    Returns:
        dict: Modelo calibrado e estat√≠sticas
    """
    try:
        # Filtrar dados v√°lidos
        mask_validas = (df_integrado['D_cm'].notna() &
                        df_integrado['altura_media'].notna() &
                        df_integrado['D_cm'] > 0)

        df_calibracao = df_integrado[mask_validas].copy()

        if len(df_calibracao) < 10:
            st.warning("‚ö†Ô∏è Poucos dados para calibra√ß√£o com LiDAR")
            return None

        # Preparar dados
        X = df_calibracao[['D_cm']].copy()
        y_lidar = df_calibracao['altura_media'].values

        # Modelo calibrado simples (linear)
        modelo_calibrado = LinearRegression()
        modelo_calibrado.fit(X, y_lidar)

        # Predi√ß√µes
        y_pred_calibrado = modelo_calibrado.predict(X)

        # Valida√ß√£o cruzada
        if CONFIGURACOES_LIDAR['parametros_calibracao']['validacao_cruzada']:
            kf = KFold(n_splits=CONFIGURACOES_LIDAR['parametros_calibracao']['k_folds'],
                       shuffle=True, random_state=42)
            cv_scores = cross_val_score(modelo_calibrado, X, y_lidar, cv=kf, scoring='r2')
            cv_score_medio = cv_scores.mean()
        else:
            cv_score_medio = None

        # Estat√≠sticas
        r2_calibrado = r2_score(y_lidar, y_pred_calibrado)
        rmse_calibrado = np.sqrt(mean_squared_error(y_lidar, y_pred_calibrado))

        resultado_calibracao = {
            'modelo_calibrado': modelo_calibrado,
            'r2_calibrado': r2_calibrado,
            'rmse_calibrado': rmse_calibrado,
            'cv_score': cv_score_medio,
            'n_dados': len(df_calibracao),
            'coeficientes': {
                'intercepto': modelo_calibrado.intercept_,
                'slope': modelo_calibrado.coef_[0]
            },
            'dados_calibracao': df_calibracao,
            'predicoes_calibradas': y_pred_calibrado
        }

        return resultado_calibracao

    except Exception as e:
        st.error(f"‚ùå Erro na calibra√ß√£o: {e}")
        return None


def analisar_estrutura_florestal_lidar(df_lidar):
    """
    An√°lise da estrutura florestal baseada em m√©tricas LiDAR

    Args:
        df_lidar: DataFrame com m√©tricas LiDAR

    Returns:
        dict: An√°lise estrutural
    """
    analise = {}

    # Estat√≠sticas b√°sicas de altura
    if 'altura_media' in df_lidar.columns:
        analise['altura'] = {
            'media_geral': df_lidar['altura_media'].mean(),
            'std_geral': df_lidar['altura_media'].std(),
            'min': df_lidar['altura_media'].min(),
            'max': df_lidar['altura_media'].max(),
            'cv': (df_lidar['altura_media'].std() / df_lidar['altura_media'].mean()) * 100
        }

    # An√°lise de cobertura
    if 'cobertura' in df_lidar.columns:
        cobertura_media = df_lidar['cobertura'].mean()
        analise['cobertura'] = {
            'media': cobertura_media,
            'classe': classificar_cobertura(cobertura_media)
        }

    # An√°lise de complexidade
    if 'complexidade' in df_lidar.columns:
        analise['complexidade'] = {
            'media': df_lidar['complexidade'].mean(),
            'distribuicao': df_lidar['classe_complexidade'].value_counts().to_dict()
        }

    # An√°lise por talh√£o
    if 'talhao' in df_lidar.columns and 'altura_media' in df_lidar.columns:
        analise_talhao = df_lidar.groupby('talhao').agg({
            'altura_media': ['mean', 'std', 'count'],
            'cobertura': 'mean' if 'cobertura' in df_lidar.columns else lambda x: None
        })

        analise['por_talhao'] = analise_talhao.to_dict()

    return analise


def classificar_cobertura(cobertura_percentual):
    """
    Classifica o n√≠vel de cobertura florestal

    Args:
        cobertura_percentual: Percentual de cobertura

    Returns:
        str: Classifica√ß√£o da cobertura
    """
    if cobertura_percentual >= 90:
        return "Muito Alta"
    elif cobertura_percentual >= 75:
        return "Alta"
    elif cobertura_percentual >= 60:
        return "M√©dia"
    elif cobertura_percentual >= 40:
        return "Baixa"
    else:
        return "Muito Baixa"


def gerar_alertas_automaticos_lidar(df_integrado, stats_comparacao):
    """
    Gera alertas autom√°ticos baseados na an√°lise LiDAR

    Args:
        df_integrado: DataFrame integrado
        stats_comparacao: Estat√≠sticas da compara√ß√£o

    Returns:
        list: Lista de alertas
    """
    alertas = []

    if stats_comparacao is None:
        alertas.append("‚ö†Ô∏è N√£o foi poss√≠vel comparar dados campo vs LiDAR")
        return alertas

    # Alerta de correla√ß√£o baixa
    if stats_comparacao['correlacao'] < THRESHOLDS_ALERTAS_LIDAR['r2_baixo']:
        alertas.append(f"üî¥ Correla√ß√£o baixa campo-LiDAR: {stats_comparacao['correlacao']:.3f}")

    # Alerta de outliers
    n_outliers = len(stats_comparacao['outliers'])
    if n_outliers > 0:
        pct_outliers = (n_outliers / stats_comparacao['n_parcelas']) * 100
        alertas.append(f"‚ö†Ô∏è {n_outliers} outliers detectados ({pct_outliers:.1f}%)")

    # Alerta de bias sistem√°tico
    if abs(stats_comparacao['diferenca_media']) > 2.0:
        tendencia = "subestima" if stats_comparacao['diferenca_media'] > 0 else "superestima"
        alertas.append(f"üìä Bias sistem√°tico: Campo {tendencia} em {abs(stats_comparacao['diferenca_media']):.1f}m")

    # Alerta de alta variabilidade
    if 'altura_media' in df_integrado.columns:
        cv_lidar = (df_integrado['altura_media'].std() / df_integrado['altura_media'].mean()) * 100
        if cv_lidar > THRESHOLDS_ALERTAS_LIDAR['cv_alto']:
            alertas.append(f"üìà Alta variabilidade LiDAR: CV = {cv_lidar:.1f}%")

    # Alerta de cobertura baixa
    if 'cobertura' in df_integrado.columns:
        cobertura_media = df_integrado['cobertura'].mean()
        if cobertura_media < THRESHOLDS_ALERTAS_LIDAR['cobertura_baixa']:
            alertas.append(f"üå≤ Cobertura baixa detectada: {cobertura_media:.1f}%")

    return alertas


def calcular_metricas_validacao_lidar(df_integrado):
    """
    Calcula m√©tricas de valida√ß√£o para dados LiDAR

    Args:
        df_integrado: DataFrame integrado

    Returns:
        dict: M√©tricas de valida√ß√£o
    """
    metricas = {}

    # Cobertura de dados LiDAR
    total_parcelas = len(df_integrado)
    parcelas_com_lidar = df_integrado['altura_media'].notna().sum()
    metricas['cobertura_lidar'] = (parcelas_com_lidar / total_parcelas) * 100

    # Qualidade das m√©tricas
    if 'altura_media' in df_integrado.columns:
        dados_altura = df_integrado['altura_media'].dropna()
        metricas['qualidade_altura'] = {
            'n_dados': len(dados_altura),
            'valores_validos': (dados_altura > 0).sum(),
            'media': dados_altura.mean(),
            'std': dados_altura.std(),
            'outliers': len(detectar_outliers_iqr(dados_altura))
        }

    # Consist√™ncia entre talh√µes
    if 'talhao' in df_integrado.columns and 'altura_media' in df_integrado.columns:
        cv_por_talhao = df_integrado.groupby('talhao')['altura_media'].apply(
            lambda x: (x.std() / x.mean()) * 100 if len(x) > 1 else 0
        )
        metricas['consistencia_talhoes'] = {
            'cv_medio': cv_por_talhao.mean(),
            'talhoes_alta_variabilidade': (cv_por_talhao > 30).sum()
        }

    return metricas


def detectar_outliers_iqr(serie):
    """
    Detecta outliers usando m√©todo IQR

    Args:
        serie: S√©rie pandas com dados

    Returns:
        Series: √çndices dos outliers
    """
    Q1 = serie.quantile(0.25)
    Q3 = serie.quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = serie[(serie < lower_bound) | (serie > upper_bound)]
    return outliers


def exportar_dados_integrados(df_integrado):
    """
    Prepara dados integrados para exporta√ß√£o

    Args:
        df_integrado: DataFrame integrado

    Returns:
        str: CSV formatado para download
    """
    # Selecionar colunas principais
    colunas_export = ['talhao', 'parcela', 'D_cm', 'H_m']

    # Adicionar colunas LiDAR dispon√≠veis
    colunas_lidar = ['altura_media', 'altura_maxima', 'desvio_altura',
                     'cobertura', 'densidade', 'complexidade']

    for col in colunas_lidar:
        if col in df_integrado.columns:
            colunas_export.append(col)

    # Adicionar m√©tricas derivadas se dispon√≠veis
    colunas_derivadas = ['heterogeneidade_vertical', 'ocupacao_vertical',
                         'razao_max_media', 'classe_complexidade']

    for col in colunas_derivadas:
        if col in df_integrado.columns:
            colunas_export.append(col)

    # Filtrar apenas colunas existentes
    colunas_existentes = [col for col in colunas_export if col in df_integrado.columns]

    df_export = df_integrado[colunas_existentes].copy()

    # Adicionar metadados
    df_export['fonte_altura'] = df_export.apply(
        lambda row: 'LiDAR' if pd.notna(row.get('altura_media')) else 'Campo',
        axis=1
    )

    df_export['data_processamento'] = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')

    return df_export.to_csv(index=False)


def gerar_relatorio_integracao_lidar(df_integrado, stats_comparacao, alertas):
    """
    Gera relat√≥rio completo da integra√ß√£o LiDAR

    Args:
        df_integrado: DataFrame integrado
        stats_comparacao: Estat√≠sticas da compara√ß√£o
        alertas: Lista de alertas

    Returns:
        str: Relat√≥rio em markdown
    """
    timestamp = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')

    relatorio = f"""# RELAT√ìRIO DE INTEGRA√á√ÉO LIDAR
**Data/Hora:** {timestamp}

## üìä RESUMO GERAL
- **Total de parcelas:** {len(df_integrado)}
- **Parcelas com dados LiDAR:** {df_integrado['altura_media'].notna().sum() if 'altura_media' in df_integrado.columns else 0}
- **Cobertura LiDAR:** {(df_integrado['altura_media'].notna().sum() / len(df_integrado)) * 100:.1f}%

## üîç COMPARA√á√ÉO CAMPO vs LIDAR
"""

    if stats_comparacao:
        relatorio += f"""
- **Correla√ß√£o:** {stats_comparacao['correlacao']:.3f}
- **R¬≤:** {stats_comparacao['r2']:.3f}
- **RMSE:** {stats_comparacao['rmse']:.2f} m
- **Diferen√ßa m√©dia:** {stats_comparacao['diferenca_media']:.2f} m
- **Diferen√ßa absoluta m√©dia:** {stats_comparacao['diferenca_abs_media']:.2f} m
- **Outliers detectados:** {len(stats_comparacao['outliers'])}

### Equa√ß√£o de Calibra√ß√£o
**H_campo = {stats_comparacao['intercepto']:.3f} + {stats_comparacao['coeficiente_angular']:.3f} √ó H_lidar**
"""
    else:
        relatorio += "\n*Compara√ß√£o n√£o dispon√≠vel - dados insuficientes*\n"

    # Alertas
    if alertas:
        relatorio += "\n## ‚ö†Ô∏è ALERTAS AUTOM√ÅTICOS\n"
        for alerta in alertas:
            relatorio += f"- {alerta}\n"

    # M√©tricas estruturais
    if 'altura_media' in df_integrado.columns:
        dados_altura = df_integrado['altura_media'].dropna()
        relatorio += f"""
## üå≤ AN√ÅLISE ESTRUTURAL
- **Altura m√©dia geral:** {dados_altura.mean():.1f} m
- **Desvio padr√£o:** {dados_altura.std():.1f} m
- **Altura m√≠nima:** {dados_altura.min():.1f} m
- **Altura m√°xima:** {dados_altura.max():.1f} m
- **Coeficiente de varia√ß√£o:** {(dados_altura.std() / dados_altura.mean()) * 100:.1f}%
"""

    # An√°lise por talh√£o
    if 'talhao' in df_integrado.columns and 'altura_media' in df_integrado.columns:
        analise_talhao = df_integrado.groupby('talhao')['altura_media'].agg(['mean', 'std', 'count']).round(2)
        relatorio += "\n## üìä AN√ÅLISE POR TALH√ÉO\n"
        for talhao, dados in analise_talhao.iterrows():
            relatorio += f"- **Talh√£o {talhao}:** {dados['mean']:.1f}m (¬±{dados['std']:.1f}m, n={dados['count']})\n"

    relatorio += f"""
## üîß CONFIGURA√á√ïES UTILIZADAS
- **Altura m√≠nima:** {CONFIGURACOES_LIDAR['limites_validacao']['altura_min']} m
- **Altura m√°xima:** {CONFIGURACOES_LIDAR['limites_validacao']['altura_max']} m
- **Threshold outliers:** {THRESHOLDS_ALERTAS_LIDAR['diferenca_altura_critica']} m
- **R¬≤ m√≠nimo:** {CONFIGURACOES_LIDAR['limites_validacao']['r2_minimo']}

---
*Relat√≥rio gerado pelo Sistema Integrado de Invent√°rio Florestal com dados LiDAR*
"""

    return relatorio